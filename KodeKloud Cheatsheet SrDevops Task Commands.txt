Task 01 - Task 36 : Kodekloud Cheatsheat SysAdmin Task Commands.txt
Task 37 - Task 87 : Kodekloud Cheatsheat DevOps Task Commands.txt
--------------------------------------------------------------------------------------------------------------------------------
Task 88: 11/Oct/2022

Init Containers in Kubernetes

There are some applications that need to be deployed on Kubernetes cluster and these apps have some pre-requisites where some configurations need to be changed before deploying the app container. Some of these changes cannot be made inside the images so the DevOps team has come up with a solution to use init containers to perform these tasks during deployment. Below is a sample scenario that the team is going to test first.

    Create a Deployment named as ic-deploy-devops.

    Configure spec as replicas should be 1, labels app should be ic-devops, template's metadata lables app should be the same ic-devops.

    The initContainers should be named as ic-msg-devops, use image debian, preferably with latest tag and use command '/bin/bash', '-c' and 'echo Init Done - Welcome to xFusionCorp Industries > /ic/news'. The volume mount should be named as ic-volume-devops and mount path should be /ic.

    Main container should be named as ic-main-devops, use image debian, preferably with latest tag and use command '/bin/bash', '-c' and 'while true; do cat /ic/news; sleep 5; done'. The volume mount should be named as ic-volume-devops and mount path should be /ic.

    Volume to be named as ic-volume-devops and it should be an emptyDir type.

Note: The kubectl utility on jump_host has been configured to work with the kubernetes cluster.


1. Check existing running services,deployment and pods
thor@jump_host ~$ kubectl get all
	NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
	service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   59m

thor@jump_host ~$ kubectl get services
	NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
	kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   59m

thor@jump_host ~$ kubectl get deploy
	No resources found in default namespace.

thor@jump_host ~$ kubectl get pods
	No resources found in default namespace.

2. Create yaml file as per requirement.
thor@jump_host ~$ vi /tmp/init.yml
 
thor@jump_host ~$ cat /tmp/init.yml 
		apiVersion: apps/v1

		kind: Deployment

		metadata:

		  name: ic-deploy-devops

		  labels:

		    app: ic-devops

		spec:

		  replicas: 1

		  selector:

		    matchLabels:

		      app: ic-devops

		  template:

		    metadata:

		      labels:

		        app: ic-devops

		    spec:

		      volumes:

		        - name: ic-volume-devops

		          emptyDir: {}

		      initContainers:

		        - name: ic-msg-devops

		          image: debian:latest

		          command:

		            [

		              "/bin/bash",

		              "-c",

		              "echo Init Done - Welcome to xFusionCorp Industries > /ic/news",

		            ]

		          volumeMounts:

		            - name: ic-volume-devops

		              mountPath: /ic

		 

		      containers:

		        - name: ic-main-devops

		          image: debian:latest

		          command:

		            [

		              "/bin/bash",

		              "-c",

		              "while true; do cat /ic/news; sleep 5; done",

		            ]

		          volumeMounts:

		            - name: ic-volume-devops

		              mountPath: /ic

3. Create pod and deployment 
thor@jump_host ~$ kubectl create -f /tmp/init.yml 
	deployment.apps/ic-deploy-devops created

4. Wait for pod to get to running status
thor@jump_host ~$ kubectl get pods -w
	NAME                                READY   STATUS    RESTARTS   AGE
	ic-deploy-devops-68f4dcbdfb-grg6v   1/1     Running   0          23s
	^C

thor@jump_host ~$ kubectl get deploy
	NAME               READY   UP-TO-DATE   AVAILABLE   AGE
	ic-deploy-devops   1/1     1            1           60s

thor@jump_host ~$ kubectl get pods
	NAME                                READY   STATUS    RESTARTS   AGE
	ic-deploy-devops-68f4dcbdfb-grg6v   1/1     Running   0          66s

5. Validate the task by checking logs on created pod and cat on created file
thor@jump_host ~$ kubectl logs -f ic-deploy-devops-68f4dcbdfb-grg6v
		Init Done - Welcome to xFusionCorp Industries
		Init Done - Welcome to xFusionCorp Industries
		Init Done - Welcome to xFusionCorp Industries
		Init Done - Welcome to xFusionCorp Industries
		Init Done - Welcome to xFusionCorp Industries
		Init Done - Welcome to xFusionCorp Industries
		Init Done - Welcome to xFusionCorp Industries
		^C

thor@jump_host ~$ kubectl exec ic-deploy-devops-68f4dcbdfb-grg6v -- cat /ic/news
		Init Done - Welcome to xFusionCorp Industries

--------------------------------------------------------------------------------------------------------------------------------
Task 89: 13/Oct/2022

Troubleshoot Issue With Pods

One of the junior DevOps team members was working on to deploy a stack on Kubernetes cluster. Somehow the pod is not coming up and its failing with some errors. We need to fix this as soon as possible. Please look into it.

    There is a pod named webserver and the container under it is named as nginx-container. It is using image nginx:latest

    There is a sidecar container as well named sidecar-container which is using ubuntu:latest image.

Look into the issue and fix it, make sure pod is in running state and you are able to access the app.

Note: The kubectl utility on jump_host has been configured to work with the kubernetes cluster.



Name:         webserver
Namespace:    default
Priority:     0
Node:         kodekloud-control-plane/172.17.0.2
Start Time:   Thu, 13 Oct 2022 12:03:02 +0000
Labels:       app=web-app
Annotations:  <none>
Status:       Pending
IP:           10.244.0.5
IPs:
  IP:  10.244.0.5
Containers:
  nginx-container:
    Container ID:   
    Image:          nginx:latests
    Image ID:       
    Port:           <none>
    Host Port:      <none>
    State:          Waiting
      Reason:       ImagePullBackOff
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/log/nginx from shared-logs (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2dgf4 (ro)
  sidecar-container:
    Container ID:  containerd://f186ca761ed3228d82850c85ff4fbf29b954ee664214699ac609288f80cfe75c
    Image:         ubuntu:latest
    Image ID:      docker.io/library/ubuntu@sha256:35fb073f9e56eb84041b0745cb714eff0f7b225ea9e024f703cab56aaa5c7720
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
      while true; do cat /var/log/nginx/access.log /var/log/nginx/error.log; sleep 30; done
    State:          Running
      Started:      Thu, 13 Oct 2022 12:03:10 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/log/nginx from shared-logs (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2dgf4 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  shared-logs:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  default-token-2dgf4:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-2dgf4
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Normal   Scheduled  61s                default-scheduler  Successfully assigned default/webserver to kodekloud-control-plane
  Normal   Pulling    60s                kubelet            Pulling image "ubuntu:latest"
  Normal   Started    53s                kubelet            Started container sidecar-container
  Normal   Pulled     53s                kubelet            Successfully pulled image "ubuntu:latest" in 6.384820926s
  Normal   Created    53s                kubelet            Created container sidecar-container
  Normal   BackOff    26s (x3 over 53s)  kubelet            Back-off pulling image "nginx:latests"
  Warning  Failed     26s (x3 over 53s)  kubelet            Error: ImagePullBackOff
  Normal   Pulling    12s (x3 over 60s)  kubelet            Pulling image "nginx:latests"
  Warning  Failed     11s (x3 over 60s)  kubelet            Failed to pull image "nginx:latests": rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/nginx:latests": failed to resolve reference "docker.io/library/nginx:latests": docker.io/library/nginx:latests: not found
  Warning  Failed     11s (x3 over 60s)  kubelet            Error: ErrImagePull


1. Check pod running status using kubectl utility
thor@jump_host ~$ kubectl get pods
	NAME        READY   STATUS             RESTARTS   AGE
	webserver   1/2     ImagePullBackOff   0          30s

thor@jump_host ~$ kubectl get pods webserver
	NAME        READY   STATUS         RESTARTS   AGE
	webserver   1/2     ErrImagePull   0          39s

2. Check pod configuration and try to indentify error
thor@jump_host ~$ kubectl describe pod webserver
		Name:         webserver
		Namespace:    default
		Priority:     0
		Node:         kodekloud-control-plane/172.17.0.2
		Start Time:   Thu, 13 Oct 2022 12:03:02 +0000
		Labels:       app=web-app
		Annotations:  <none>
		Status:       Pending
		IP:           10.244.0.5
		IPs:
		  IP:  10.244.0.5
		Containers:
		|------------------------------------------------------------------------------------------------------------------------
		| nginx-container:
		|   Container ID:   
		|   Image:          nginx:latests											<-------- Error in container image name
		|   Image ID:       
		|   Port:           <none>
		|   Host Port:      <none>
		|   State:          Waiting
		|     Reason:       ImagePullBackOff
		|   Ready:          False
		|   Restart Count:  0
		|   Environment:    <none>
		|   Mounts:
		|     /var/log/nginx from shared-logs (rw)
		|     /var/run/secrets/kubernetes.io/serviceaccount from default-token-2dgf4 (ro)
		|------------------------------------------------------------------------------------------------------------------------      
		  sidecar-container:
		    Container ID:  containerd://f186ca761ed3228d82850c85ff4fbf29b954ee664214699ac609288f80cfe75c
		    Image:         ubuntu:latest
		    Image ID:      docker.io/library/ubuntu@sha256:35fb073f9e56eb84041b0745cb714eff0f7b225ea9e024f703cab56aaa5c7720
		    Port:          <none>
		    Host Port:     <none>
		    Command:
		      sh
		      -c
		      while true; do cat /var/log/nginx/access.log /var/log/nginx/error.log; sleep 30; done
		    State:          Running
		      Started:      Thu, 13 Oct 2022 12:03:10 +0000
		    Ready:          True
		    Restart Count:  0
		    Environment:    <none>
		    Mounts:
		      /var/log/nginx from shared-logs (rw)
		      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2dgf4 (ro)
		Conditions:
		  Type              Status
		  Initialized       True 
		  Ready             False 
		  ContainersReady   False 
		  PodScheduled      True 
		Volumes:
		  shared-logs:
		    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
		    Medium:     
		    SizeLimit:  <unset>
		  default-token-2dgf4:
		    Type:        Secret (a volume populated by a Secret)
		    SecretName:  default-token-2dgf4
		    Optional:    false
		QoS Class:       BestEffort
		Node-Selectors:  <none>
		Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
		                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
		Events:
		  Type     Reason     Age                From               Message
		  ----     ------     ----               ----               -------
		  Normal   Scheduled  61s                default-scheduler  Successfully assigned default/webserver to kodekloud-control-plane
		  Normal   Pulling    60s                kubelet            Pulling image "ubuntu:latest"
		  Normal   Started    53s                kubelet            Started container sidecar-container
		  Normal   Pulled     53s                kubelet            Successfully pulled image "ubuntu:latest" in 6.384820926s
		  Normal   Created    53s                kubelet            Created container sidecar-container
		  Normal   BackOff    26s (x3 over 53s)  kubelet            Back-off pulling image "nginx:latests"
		  Warning  Failed     26s (x3 over 53s)  kubelet            Error: ImagePullBackOff
		  Normal   Pulling    12s (x3 over 60s)  kubelet            Pulling image "nginx:latests"
		  Warning  Failed     11s (x3 over 60s)  kubelet            Failed to pull image "nginx:latests": rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/nginx:latests": failed to resolve reference "docker.io/library/nginx:latests": docker.io/library/nginx:latests: not found
		  Warning  Failed     11s (x3 over 60s)  kubelet            Error: ErrImagePull


3. Edit the pod to change the container image name (using vi editor or default editor)
thor@jump_host ~$ kubectl edit pod webserver
		pod/webserver edited

4. Wait for pod to running status
thor@jump_host ~$ kubectl get pod webserver
		NAME        READY   STATUS    RESTARTS   AGE
		webserver   2/2     Running   0          2m22s

thor@jump_host ~$ kubectl describe pod webserver
		Name:         webserver
		Namespace:    default
		Priority:     0
		Node:         kodekloud-control-plane/172.17.0.2
		Start Time:   Thu, 13 Oct 2022 12:03:02 +0000
		Labels:       app=web-app
		Annotations:  <none>
		Status:       Running
		IP:           10.244.0.5
		IPs:
		  IP:  10.244.0.5
		Containers:
		|------------------------------------------------------------------------------------------------------------------------
		| nginx-container:																										
		|   Container ID:   containerd://96e18a2d97d0dcd78289713a2656e1150b4615dd6139fc56c293bc283e147616							
		|   Image:          nginx:latest
		|   Image ID:       docker.io/library/nginx@sha256:2f770d2fe27bc85f68fd7fe6a63900ef7076bc703022fe81b980377fe3d27b70
		|   Port:           <none>
		|   Host Port:      <none>
		|   State:          Running																		<------------Error resolved, pod running
		|     Started:      Thu, 13 Oct 2022 12:05:22 +0000
		|   Ready:          True
		|   Restart Count:  0
		|   Environment:    <none>
		|   Mounts:
		|     /var/log/nginx from shared-logs (rw)
		|     /var/run/secrets/kubernetes.io/serviceaccount from default-token-2dgf4 (ro)
		|------------------------------------------------------------------------------------------------------------------------|
		  sidecar-container:
		    Container ID:  containerd://f186ca761ed3228d82850c85ff4fbf29b954ee664214699ac609288f80cfe75c
		    Image:         ubuntu:latest
		    Image ID:      docker.io/library/ubuntu@sha256:35fb073f9e56eb84041b0745cb714eff0f7b225ea9e024f703cab56aaa5c7720
		    Port:          <none>
		    Host Port:     <none>
		    Command:
		      sh
		      -c
		      while true; do cat /var/log/nginx/access.log /var/log/nginx/error.log; sleep 30; done
		    State:          Running
		      Started:      Thu, 13 Oct 2022 12:03:10 +0000
		    Ready:          True
		    Restart Count:  0
		    Environment:    <none>
		    Mounts:
		      /var/log/nginx from shared-logs (rw)
		      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2dgf4 (ro)
		Conditions:
		  Type              Status
		  Initialized       True 
		  Ready             True 
		  ContainersReady   True 
		  PodScheduled      True 
		Volumes:
		  shared-logs:
		    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
		    Medium:     
		    SizeLimit:  <unset>
		  default-token-2dgf4:
		    Type:        Secret (a volume populated by a Secret)
		    SecretName:  default-token-2dgf4
		    Optional:    false
		QoS Class:       BestEffort
		Node-Selectors:  <none>
		Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
		                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
		Events:
		  Type     Reason     Age                  From               Message
		  ----     ------     ----                 ----               -------
		  Normal   Scheduled  2m28s                default-scheduler  Successfully assigned default/webserver to kodekloud-control-plane
		  Normal   Pulling    2m27s                kubelet            Pulling image "ubuntu:latest"
		  Normal   Started    2m20s                kubelet            Started container sidecar-container
		  Normal   Pulled     2m20s                kubelet            Successfully pulled image "ubuntu:latest" in 6.384820926s
		  Normal   Created    2m20s                kubelet            Created container sidecar-container
		  Normal   Pulling    99s (x3 over 2m27s)  kubelet            Pulling image "nginx:latests"
		  Warning  Failed     98s (x3 over 2m27s)  kubelet            Failed to pull image "nginx:latests": rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/nginx:latests": failed to resolve reference "docker.io/library/nginx:latests": docker.io/library/nginx:latests: not found
		  Warning  Failed     98s (x3 over 2m27s)  kubelet            Error: ErrImagePull
		  Normal   BackOff    62s (x6 over 2m20s)  kubelet            Back-off pulling image "nginx:latests"
		  Warning  Failed     62s (x6 over 2m20s)  kubelet            Error: ImagePullBackOff

thor@jump_host ~$ kubectl get pods
	NAME        READY   STATUS    RESTARTS   AGE
	webserver   2/2     Running   0          3m46s

--------------------------------------------------------------------------------------------------------------------------------
Task 90: 15/Oct/2022

Persistent Volumes in Kubernetes HTTPD

The Nautilus DevOps team is working on a Kubernetes template to deploy a web application on the cluster. There are some requirements to create/use persistent volumes to store the application code, and the template needs to be designed accordingly. Please find more details below:

    Create a PersistentVolume named as pv-datacenter. Configure the spec as storage class should be manual, set capacity to 5Gi, set access mode to ReadWriteOnce, volume type should be hostPath and set path to /mnt/itadmin (this directory is already created, you might not be able to access it directly, so you need not to worry about it).

    Create a PersistentVolumeClaim named as pvc-datacenter. Configure the spec as storage class should be manual, request 1Gi of the storage, set access mode to ReadWriteOnce.

    Create a pod named as pod-datacenter, mount the persistent volume you created with claim name pvc-datacenter at document root of the web server, the container within the pod should be named as container-datacenter using image httpd with latest tag only (remember to mention the tag i.e httpd:latest).

    Create a node port type service named web-datacenter using node port 30008 to expose the web server running within the pod.

Note: The kubectl utility on jump_host has been configured to work with the kubernetes cluster.

1. Check kubectl utility for currently running services and pods
thor@jump_host ~$ kubectl get all
	NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
	service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   65m
 
thor@jump_host ~$ kubectl get pvc
	No resources found in default namespace.

2. Create YAML file as per requirements 
thor@jump_host ~$ vi /tmp/pvc_httpd.yml

thor@jump_host ~$ cat /tmp/pvc_httpd.yml 
		---
		apiVersion: v1
		kind: PersistentVolume
		metadata:
		  name: pv-datacenter
		spec:
		  capacity:
		    storage: 5Gi
		  accessModes:
		    - ReadWriteOnce
		  storageClassName: manual
		  hostPath:
		    path: /mnt/itadmin
		---
		apiVersion: v1
		kind: PersistentVolumeClaim
		metadata:
		  name: pvc-datacenter
		spec:
		  accessModes:
		    - ReadWriteOnce
		  storageClassName: manual
		  resources:
		    requests:
		      storage: 1Gi
		---
		apiVersion: v1
		kind: Pod
		metadata:
		  name: pod-datacenter
		  labels:
		     app: httpd
		spec:
		  volumes:
		    - name: storage-datacenter
		      persistentVolumeClaim:
		        claimName: pvc-datacenter
		  containers:
		    - name: container-datacenter
		      image: httpd:latest
		      ports:
		        - containerPort: 80
		      volumeMounts:
		        - name: storage-datacenter
		          mountPath:  /usr/local/apache2/htdocs/
		---                                                                                                           
		apiVersion: v1                                                                                                
		kind: Service                                                                                                 
		metadata:                                                                                                     
		  name: web-datacenter                                                                                         
		spec:                                                                                                         
		   type: NodePort                                                                                             
		   selector:                                                                                                  
		     app: httpd                                                                                     
		   ports:                                                                                                     
		     - port: 80                                                                                               
		       targetPort: 80                                                                                         
		       nodePort: 30008

3. Create the deployment , pods and persistent volumes
thor@jump_host ~$ kubectl create -f /tmp/pvc_httpd.yml 
	persistentvolume/pv-datacenter created
	persistentvolumeclaim/pvc-datacenter created
	pod/pod-datacenter created
	service/web-datacenter created

4. Wait for pods and services to running status
thor@jump_host ~$ kubectl get all
		NAME                 READY   STATUS    RESTARTS   AGE
		pod/pod-datacenter   0/1     Pending   0          6s

		NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
		service/kubernetes       ClusterIP   10.96.0.1       <none>        443/TCP        72m
		service/web-datacenter   NodePort    10.96.147.100   <none>        80:30008/TCP   6s

 
thor@jump_host ~$ kubectl get all
	NAME                 READY   STATUS    RESTARTS   AGE
	pod/pod-datacenter   1/1     Running   0          30s

	NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
	service/kubernetes       ClusterIP   10.96.0.1       <none>        443/TCP        73m
	service/web-datacenter   NodePort    10.96.147.100   <none>        80:30008/TCP   30s

5. Validate Psersistent Volume Claim and Peristent volume 
thor@jump_host ~$ kubectl get pvc
	NAME             STATUS   VOLUME          CAPACITY   ACCESS MODES   STORAGECLASS   AGE
	pvc-datacenter   Bound    pv-datacenter   5Gi        RWO            manual         40s
 
thor@jump_host ~$ kubectl get pv
	NAME            CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                    STORAGECLASS   REASON   AGE
	pv-datacenter   5Gi        RWO            Retain           Bound    default/pvc-datacenter   manual                  45s

6. Validate task by View port on website

--------------------------------------------------------------------------------------------------------------------------------
Task 91: 17/Oct/2022

Resolve Git Merge Conflicts

Sarah and Max were working on writting some stories which they have pushed to the repository. Max has recently added some new changes and is trying to push them to the repository but he is facing some issues. Below you can find more details:

SSH into storage server using user max and password Max_pass123. Under /home/max you will find the story-blog repository. Try to push the changes to the origin repo and fix the issues. The story-index.txt must have titles for all 4 stories. Additionally, there is a typo in The Lion and the Mooose line where Mooose should be Mouse.

Click on the Gitea UI button on the top bar. You should be able to access the Gitea page. You can login to Gitea server from UI using username sarah and password Sarah_pass123 or username max and password Max_pass123.

Note: For these kind of scenarios requiring changes to be done in a web UI, please take screenshots so that you can share it with us for review in case your task is marked incomplete. You may also consider using a screen recording software such as loom.com to record and share your work.

1. SSH to storage server with user max
thor@jump_host ~$ ssh max@ststor01
		The authenticity of host 'ststor01 (172.16.238.15)' can't be established.
		ECDSA key fingerprint is SHA256:0z85j/k+4Nf8WKbHJzxo1AOv4FeRA8LPET2N3BEkYyo.
		ECDSA key fingerprint is MD5:74:e6:4d:c4:b3:80:07:be:03:30:0a:bf:1e:eb:e6:82.
		Are you sure you want to continue connecting (yes/no)? yes
		Warning: Permanently added 'ststor01,172.16.238.15' (ECDSA) to the list of known hosts.
max@ststor01's password: 
		Welcome to xFusionCorp Storage server.

2. Go to local git repo and check git status
max $ cd /home/max/story-blog/

max (master)$ ls -ahl
		total 32
		drwxr-sr-x    3 max      max         4.0K Oct 17 14:06 .
		drwxr-sr-x    1 max      max         4.0K Oct 17 14:06 ..
		drwxr-sr-x    8 max      max         4.0K Oct 17 14:06 .git
		-rw-r--r--    1 max      max          807 Oct 17 14:06 fox-and-grapes.txt
		-rw-r--r--    1 max      max          792 Oct 17 14:06 frogs-and-ox.txt
		-rw-r--r--    1 max      max         1.1K Oct 17 14:06 lion-and-mouse.txt
		-rw-r--r--    1 max      max          102 Oct 17 14:06 story-index.txt

max (master)$ git status
		On branch master
		Your branch is ahead of 'origin/master' by 1 commit.
		  (use "git push" to publish your local commits)
		nothing to commit, working directory clean
 
3.Check story-index.txt file
max (master)$ cat story-index.txt 
		1. The Lion and the Mooose
		2. The Frogs and the Ox
		3. The Fox and the Grapes
		4. The Donkey and the Dog

4. Try to push the changes to know the error		
max (master)$ git push
		Username for 'http://git.stratos.xfusioncorp.com': max
		Password for 'http://max@git.stratos.xfusioncorp.com': 
		To http://git.stratos.xfusioncorp.com/sarah/story-blog.git
		 ! [rejected]        master -> master (fetch first)
		error: failed to push some refs to 'http://git.stratos.xfusioncorp.com/sarah/story-blog.git'
		hint: Updates were rejected because the remote contains work that you do
		hint: not have locally. This is usually caused by another repository pushing
		hint: to the same ref. You may want to first integrate the remote changes
		hint: (e.g., 'git pull ...') before pushing again.
		hint: See the 'Note about fast-forwards' in 'git push --help' for details.

5. Conflict in between local repo and Gitex repo. Setglobal variables 

max (master)$ git config --global --add user.email max@stratos.xfusioncorp.com

max (master)$ git config --global --add user.name max

max (master)$ git config -l
	user.email=max@stratos.xfusioncorp.com
	user.name=max
	core.repositoryformatversion=0
	core.filemode=true
	core.bare=false
	core.logallrefupdates=true
	remote.origin.url=http://git.stratos.xfusioncorp.com/sarah/story-blog.git
	remote.origin.fetch=+refs/heads/*:refs/remotes/origin/*
	branch.master.remote=origin
	branch.master.merge=refs/heads/master

6. Pull the changes from gitex to local 
max (master)$ git  pull origin master
	remote: Enumerating objects: 4, done.
	remote: Counting objects: 100% (4/4), done.
	remote: Compressing objects: 100% (3/3), done.
	remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0
	Unpacking objects: 100% (3/3), done.
	From http://git.stratos.xfusioncorp.com/sarah/story-blog
	 * branch            master     -> FETCH_HEAD
	   9f02757..7edc0ea  master     -> origin/master
	Auto-merging story-index.txt
	CONFLICT (add/add): Merge conflict in story-index.txt
	Automatic merge failed; fix conflicts and then commit the result.

7. Conflict while merging story-index.txt. Edit and clear those conflict

max (master)$ vi story-index.txt

max (master)$ cat story-index.txt 
	1. The Lion and the Mouse
	2. The Frogs and the Ox
	3. The Fox and the Grapes
	4. The Donkey and the Dog

8. Push the changes back to remote repository

max (master)$ git add story-index.txt 

max (master)$ git commit -m "Fixed the issue"
	[master cf96f89] Fixed the issue
	 1 file changed, 6 deletions(-)

max (master)$ git push origin  master
	Username for 'http://git.stratos.xfusioncorp.com': max
	Password for 'http://max@git.stratos.xfusioncorp.com': 
	Counting objects: 3, done.
	Delta compression using up to 36 threads.
	Compressing objects: 100% (3/3), done.
	Writing objects: 100% (3/3), 280 bytes | 0 bytes/s, done.
	Total 3 (delta 2), reused 0 (delta 0)
	remote: . Processing 1 references
	remote: Processed 1 references in total
	To http://git.stratos.xfusioncorp.com/sarah/story-blog.git
	   acefab2..cf96f89  master -> master
 
max (master)$ git status
	On branch master
	Your branch is up-to-date with 'origin/master'.
	nothing to commit, working directory clean

max (master)$ git pull origin  master
	From http://git.stratos.xfusioncorp.com/sarah/story-blog
	 * branch            master     -> FETCH_HEAD
	Already up-to-date.
 
max (master)$ git status
	On branch master
	Your branch is up-to-date with 'origin/master'.
	nothing to commit, working directory clean

max (master)$ 

--------------------------------------------------------------------------------------------------------------------------------
Task 92: 19/Oct/2022

Managing Jinja2 Templates Using Ansible

One of the Nautilus DevOps team members is working on to develop a role for httpd installation and configuration. Work is almost completed, however there is a requirement to add a jinja2 template for index.html file. Additionally, the relevant task needs to be added inside the role. The inventory file ~/ansible/inventory is already present on jump host that can be used. Complete the task as per details mentioned below:

a. Update ~/ansible/playbook.yml playbook to run the httpd role on App Server 1.

b. Create a jinja2 template index.html.j2 under /home/thor/ansible/role/httpd/templates/ directory and add a line This file was created using Ansible on <respective server> (for example This file was created using Ansible on stapp01 in case of App Server 1). Also please make sure not to hard code the server name inside the template. Instead, use inventory_hostname variable to fetch the correct value.

c. Add a task inside /home/thor/ansible/role/httpd/tasks/main.yml to copy this template on App Server 1 under /var/www/html/index.html. Also make sure that /var/www/html/index.html file's permissions are 0777.

d. The user/group owner of /var/www/html/index.html file must be respective sudo user of the server (for example tony in case of stapp01).

Note: Validation will try to run the playbook using command ansible-playbook -i inventory playbook.yml so please make sure the playbook works this way without passing any extra arguments.


1. Go to mentioned folder and verify playbook and inventory

thor@jump_host ~$ cd /home/thor/ansible/

thor@jump_host ~/ansible$ ls -ahl
		total 20K
		drwxr-xr-x 3 thor thor 4.0K Oct 19 05:55 .
		drwxr----- 1 thor thor 4.0K Oct 19 05:55 ..
		-rw-r--r-- 1 thor thor  237 Oct 19 05:55 inventory
		-rw-r--r-- 1 thor thor   73 Oct 19 05:55 playbook.yml
		drwxr-xr-x 3 thor thor 4.0K Oct 19 05:55 role

thor@jump_host ~/ansible$ cat inventory 
		stapp01 ansible_host=172.16.238.10 ansible_user=tony ansible_ssh_pass=Ir0nM@n
		stapp02 ansible_host=172.16.238.11 ansible_user=steve ansible_ssh_pass=Am3ric@
		stapp03 ansible_host=172.16.238.12 ansible_user=banner ansible_ssh_pass=BigGr33n

 
thor@jump_host ~/ansible$ cat playbook.yml 
		---
		- hosts: 
		  become: yes
		  become_user: root
		  roles:
		    - role/httpd

2. Edit the playbook to add the mentioned host (stapp01)

thor@jump_host ~/ansible$ vi playbook.yml 

thor@jump_host ~/ansible$ cat playbook.yml 
		---
		- hosts: stapp01						<--------------------------
		  become: yes
		  become_user: root
		  roles:
		    - role/httpd

3. Create Jinja2 template with mentioned content

thor@jump_host ~/ansible$ vi /home/thor/ansible/role/httpd/templates/index.html.j2

thor@jump_host ~/ansible$ cat /home/thor/ansible/role/httpd/templates/index.html.j2
		This file was created using Ansible on {{ ansible_hostname }}


4. Edit the mian.yml file to add a task to copy the Jinja2 template  

thor@jump_host ~/ansible$ vi /home/thor/ansible/role/httpd/tasks/main.yml

thor@jump_host ~/ansible$ cat /home/thor/ansible/role/httpd/tasks/main.yml
		---
		# tasks file for role/test

		- name: install the latest version of HTTPD
		  yum:
		    name: httpd
		    state: latest

		- name: Start service httpd
		  service:
		    name: httpd
		    state: started

		- name: Use Jinja2 template to generate index.html
		  template:
		    src: /home/thor/ansible/role/httpd/templates/index.html.j2
		    dest: /var/www/html/index.html
		    mode: "0777"
		    owner: "{{ ansible_user }}"
		    group: "{{ ansible_user }}"


5. Run the playbook

thor@jump_host ~/ansible$ ansible-playbook -i inventory playbook.yml 

		PLAY [stapp01] ******************************************************************************************************************************

		TASK [Gathering Facts] **********************************************************************************************************************
		ok: [stapp01]

		TASK [role/httpd : install the latest version of HTTPD] *************************************************************************************
		changed: [stapp01]

		TASK [role/httpd : Start service httpd] *****************************************************************************************************
		changed: [stapp01]

		TASK [role/httpd : Use Jinja2 template to generate index.html] ******************************************************************************
		changed: [stapp01]

		PLAY RECAP **********************************************************************************************************************************
		stapp01                    : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


6. Validate the changes on app server

thor@jump_host ~/ansible$ ansible stapp01 -i inventory  -a "cat /var/www/html/index.html"
		stapp01 | CHANGED | rc=0 >>
		This file was created using Ansible on stapp01

thor@jump_host ~/ansible$ ansible stapp01 -i inventory  -a "ls -ahl /var/www/html/index.html"
		stapp01 | CHANGED | rc=0 >>
		-rwxrwxrwx 1 tony tony 47 Oct 19 06:03 /var/www/html/index.html

thor@jump_host ~/ansible$ ansible stapp02 -i inventory  -a "cat /var/www/html/index.html"
		stapp02 | FAILED | rc=1 >>
		cat: /var/www/html/index.html: No such file or directorynon-zero return code

thor@jump_host ~/ansible$ ansible stapp03 -i inventory  -a "cat /var/www/html/index.html"
		stapp03 | FAILED | rc=1 >>
		cat: /var/www/html/index.html: No such file or directorynon-zero return code

--------------------------------------------------------------------------------------------------------------------------------
Task 93: 20/Oct/2022

Ansible Inventory Update

The Nautilus DevOps team has started testing their Ansible playbooks on different servers within the stack. They have placed some playbooks under /home/thor/playbook/ directory on jump host which they want to test. Some of these playbooks have already been tested on different servers, but now they want to test them on app server 3 in Stratos DC. However, they first need to create an inventory file so that Ansible can connect to the respective app. Below are some requirements:

a. Create an ini type Ansible inventory file /home/thor/playbook/inventory on jump host.

b. Add App Server 3 in this inventory along with required variables that are needed to make it work.

c. The inventory hostname of the host should be the server name as per the wiki, for example stapp01 for app server 1 in Stratos DC.

Note: Validation will try to run the playbook using command ansible-playbook -i inventory playbook.yml so please make sure the playbook works this way without passing any extra arguments.


1. Verify mentioned playbook and other files 

thor@jump_host ~$ cd /home/thor/playbook/

thor@jump_host ~/playbook$ ls -ahl
		total 16K
		drwxr-xr-x 2 thor thor 4.0K Oct 20 09:36 .
		drwxr----- 1 thor thor 4.0K Oct 20 09:36 ..
		-rw-r--r-- 1 thor thor   36 Oct 20 09:36 ansible.cfg
		-rw-r--r-- 1 thor thor  250 Oct 20 09:36 playbook.yml

thor@jump_host ~/playbook$ cat playbook.yml 
		---
		- hosts: all
		  become: yes
		  become_user: root
		  tasks:
		    - name: Install httpd package    
		      yum: 
		        name: httpd 
		        state: installed
		    
		    - name: Start service httpd
		      service:
		        name: httpd
		        state: started

2. Create the mentioned inventory file with App Server 3 details

thor@jump_host ~/playbook$ vi /home/thor/playbook/inventory

thor@jump_host ~/playbook$ cat /home/thor/playbook/inventory
		stapp03 ansible_host=172.16.238.12 ansible_ssh_pass=BigGr33n  ansible_user=banner

3. Exectue the playbook and verify.

thor@jump_host ~/playbook$ ansible-playbook -i inventory playbook.yml

		PLAY [all] **********************************************************************************************************************************

		TASK [Gathering Facts] **********************************************************************************************************************
		ok: [stapp03]

		TASK [Install httpd package] ****************************************************************************************************************
		changed: [stapp03]

		TASK [Start service httpd] ******************************************************************************************************************
		changed: [stapp03]

		PLAY RECAP **********************************************************************************************************************************
		stapp03                    : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

thor@jump_host ~/playbook$

--------------------------------------------------------------------------------------------------------------------------------
Task 94: 22/Oct/2022

Git Fork a Repository


There is a Git server used by the Nautilus project teams. Recently a new developer Jon joined the team and needs to start working on a project. To do so, he needs to fork an existing Git repository. Below you can find more details:

    Click on the Gitea UI button on the top bar. You should be able to access the Gitea page.

    Login to Gitea server using username jon and password Jon_pass123.

    There you will see a Git repository sarah/story-blog, fork it under jon user.

Note: For these kind of scenarios requiring changes to be done in a web UI, please take screenshots so that you can share it with us for review in case your task is marked incomplete. You may also consider using a screen recording software such as loom.com to record and share your work.


1. As mentioned open Gitea UI

2. Login to Gitea server using username jon and password Jon_pass123

3. Go to repo sarah/story-blog

4. Right top corner option for fork the repo

5. The new forked repo will be under jon/story-blog

--------------------------------------------------------------------------------------------------------------------------------
Task 95: 23/Oct/2022

Create a Docker Image From Container

One of the Nautilus developer was working to test new changes on a container. He wants to keep a backup of his changes to the container. A new request has been raised for the DevOps team to create a new image from this container. Below are more details about it:

a. Create an image apps:xfusion on Application Server 2 from a container ubuntu_latest that is running on same server.


1. 1. Login on app server  & Switch to  root user

thor@jump_host ~$ ssh steve@stapp02
		The authenticity of host 'stapp02 (172.16.238.11)' can't be established.
		ECDSA key fingerprint is SHA256:LmeMEQk6Mx7vqZWW6o6Knsvsgqwb4FlOk7e/cSvtfms.
		ECDSA key fingerprint is MD5:b8:e8:31:0f:29:8b:c7:be:26:6e:42:aa:56:51:29:8c.
		Are you sure you want to continue connecting (yes/no)? yes
		Warning: Permanently added 'stapp02,172.16.238.11' (ECDSA) to the list of known hosts.
		steve@stapp02's password: 

[steve@stapp02 ~]$ sudo su -

		We trust you have received the usual lecture from the local System
		Administrator. It usually boils down to these three things:

		    #1) Respect the privacy of others.
		    #2) Think before you type.
		    #3) With great power comes great responsibility.

		[sudo] password for steve: 


2. Check existing docker container ubuntu_latest running status 

[root@stapp02 ~]# docker ps 
		CONTAINER ID   IMAGE     COMMAND   CREATED              STATUS              PORTS     NAMES
		e2d2e33ed57c   ubuntu    "bash"    About a minute ago   Up About a minute             ubuntu_latest

3. Check current docker images on your system

[root@stapp02 ~]# docker images
		REPOSITORY   TAG       IMAGE ID       CREATED       SIZE
		ubuntu       latest    216c552ea5ba   2 weeks ago   77.8MB

4. Create new image from given contianer as per task

[root@stapp02 ~]# docker commit ubuntu_latest apps:xfusion
		sha256:2158e1542b17e48950a0c1fd45ab50729fbd9dd344210b5771b0113955100168

5. Verify and validate the new  docker image created on your system

[root@stapp02 ~]# docker images
		REPOSITORY   TAG       IMAGE ID       CREATED         SIZE
		apps         xfusion   2158e1542b17   6 seconds ago   116MB
		ubuntu       latest    216c552ea5ba   2 weeks ago     77.8MB

--------------------------------------------------------------------------------------------------------------------------------
Task 96: 25/Oct/2022

Puppet Multi-Packages Installation

Some new changes need to be made on some of the app servers in Stratos Datacenter. There are some packages that need to be installed on the app server 2. We want to install these packages using puppet only.

    Puppet master is already installed on Jump Server.

    Create a puppet programming file blog.pp under /etc/puppetlabs/code/environments/production/manifests on master node i.e on Jump Server and perform below mentioned tasks using the same.

    Define a class multi_package_node for agent node 2 i.e app server 2. Install net-tools and unzip packages on the agent node 2.

Notes: :- Please make sure to run the puppet agent test using sudo on agent nodes, otherwise you can face certificate issues. In that case you will have to clean the certificates first and then you will be able to run the puppet agent test.

:- Before clicking on the Check button please make sure to verify puppet server and puppet agent services are up and running on the respective servers, also please make sure to run puppet agent test to apply/test the changes manually first.

:- Please note that once lab is loaded, the puppet server service should start automatically on puppet master server, however it can take upto 2-3 minutes to start.


1. Switch to root user on jump host to create puppet programming file

thor@jump_host ~$ sudo su - 

		We trust you have received the usual lecture from the local System
		Administrator. It usually boils down to these three things:

		    #1) Respect the privacy of others.
		    #2) Think before you type.
		    #3) With great power comes great responsibility.

		[sudo] password for thor: 

2. Go to mentione folder location and create blog.pp  file with given requirements

root@jump_host ~# cd /etc/puppetlabs/code/environments/production/manifests/
 
root@jump_host /etc/puppetlabs/code/environments/production/manifests# ls -ahl
		total 8.0K
		drwxr-xr-x 1 puppet puppet 4.0K Jul 13  2021 .
		drwxr-xr-x 1 puppet puppet 4.0K Aug  9  2021 ..
 
root@jump_host /etc/puppetlabs/code/environments/production/manifests# vi blog.pp

root@jump_host /etc/puppetlabs/code/environments/production/manifests# cat blog.pp 
		class multi_package_node {
		$multi_package = [ 'net-tools', 'unzip']
		    package { $multi_package: ensure => 'installed' }
		}

		node 'stapp02.stratos.xfusioncorp.com' {
		  include multi_package_node
		}

3. Login to ap server 2 and switch to root user

root@jump_host /etc/puppetlabs/code/environments/production/manifests# ssh steve@stapp02
		The authenticity of host 'stapp02 (172.16.238.11)' can't be established.
		ECDSA key fingerprint is SHA256:JGrKQGk9+m0eDIxj8Ttwk2oL5abYgUcCazjXSp36dxs.
		ECDSA key fingerprint is MD5:ec:b0:32:f5:c4:6d:68:07:03:f0:ad:7a:a6:a7:f9:47.
		Are you sure you want to continue connecting (yes/no)? yes
		Warning: Permanently added 'stapp02,172.16.238.11' (ECDSA) to the list of known hosts.
		steve@stapp02's password: 

[steve@stapp02 ~]$ sudo su -

		We trust you have received the usual lecture from the local System
		Administrator. It usually boils down to these three things:

		    #1) Respect the privacy of others.
		    #2) Think before you type.
		    #3) With great power comes great responsibility.

		[sudo] password for steve: 

4. Check if given packages are already  installed

[root@stapp02 ~]# rpm -qa|grep -e net-tools -e unzip

5. Run the puppet agent to pull configuration from puppet server 

[root@stapp02 ~]# puppet agent -tv
		Info: Using configured environment 'production'
		Info: Retrieving pluginfacts
		Info: Retrieving plugin
		Info: Retrieving locales
		Info: Caching catalog for stapp02.stratos.xfusioncorp.com
		Info: Applying configuration version '1666708349'
		Notice: /Stage[main]/Multi_package_node/Package[net-tools]/ensure: created
		Notice: /Stage[main]/Multi_package_node/Package[unzip]/ensure: created
		Notice: Applied catalog in 14.67 seconds

6. Validate the task by checking required packages installed

[root@stapp02 ~]# rpm -qa|grep -e net-tools -e unzip
		unzip-6.0-24.el7_9.x86_64
		net-tools-2.0-0.25.20131004git.el7.x86_64

[root@stapp02 ~]#

--------------------------------------------------------------------------------------------------------------------------------
Task 97: 27/Oct/2022

Puppet Add Users


A new teammate has joined the Nautilus application development team, the application development team has asked the DevOps team to create a new user account for the new teammate on application server 1 in Stratos Datacenter. The task needs to be performed using Puppet only. You can find more details below about the task.

Create a Puppet programming file official.pp under /etc/puppetlabs/code/environments/production/manifests directory on master node i.e Jump Server, and using Puppet user resource add a user on all app servers as mentioned below:

    Create a user ravi and set its UID to 1879 on Puppet agent nodes 1 i.e App Servers 1.

Notes: :- Please make sure to run the puppet agent test using sudo on agent nodes, otherwise you can face certificate issues. In that case you will have to clean the certificates first and then you will be able to run the puppet agent test.

:- Before clicking on the Check button please make sure to verify puppet server and puppet agent services are up and running on the respective servers, also please make sure to run puppet agent test to apply/test the changes manually first.

:- Please note that once lab is loaded, the puppet server service should start automatically on puppet master server, however it can take upto 2-3 minutes to start.


1. Switch to root user and go to mentioned folder

thor@jump_host ~$ sudo su -

		We trust you have received the usual lecture from the local System
		Administrator. It usually boils down to these three things:

		    #1) Respect the privacy of others.
		    #2) Think before you type.
		    #3) With great power comes great responsibility.

		[sudo] password for thor: 
 
root@jump_host ~# cd /etc/puppetlabs/code/environments/production/manifests/

root@jump_host /etc/puppetlabs/code/environments/production/manifests# ls -ahl
		total 8.0K
		drwxr-xr-x 1 puppet puppet 4.0K Jul 13  2021 .
		drwxr-xr-x 1 puppet puppet 4.0K Aug  9  2021 ..

2. Create the mentioned puppet programming file with given requirements 

root@jump_host /etc/puppetlabs/code/environments/production/manifests# vi official.pp

root@jump_host /etc/puppetlabs/code/environments/production/manifests# cat official.pp
		class user_creator {
			user { 'ravi':
						ensure   => present,
						uid => 1879,
		  }
		}

		node 'stapp01.stratos.xfusioncorp.com' {
			include user_creator
		}

3. Validate the puppet programming file 

root@jump_host /etc/puppetlabs/code/environments/production/manifests# puppet parser validate official.pp 

4. Login to app server 01 and switch to root 

root@jump_host /etc/puppetlabs/code/environments/production/manifests# ssh tony@stapp01
		The authenticity of host 'stapp01 (172.16.238.10)' can't be established.
		ECDSA key fingerprint is SHA256:CxGn3WKmroQOoXAC5aufEdVzoDTknATLtoQHDcP0WEI.
		ECDSA key fingerprint is MD5:f1:cb:d0:b8:e6:b4:74:04:70:d2:ba:4f:12:ce:a3:23.
		Are you sure you want to continue connecting (yes/no)? yes
		Warning: Permanently added 'stapp01,172.16.238.10' (ECDSA) to the list of known hosts.
		tony@stapp01's password: 

[tony@stapp01 ~]$ sudo su -

		We trust you have received the usual lecture from the local System
		Administrator. It usually boils down to these three things:

		    #1) Respect the privacy of others.
		    #2) Think before you type.
		    #3) With great power comes great responsibility.

		[sudo] password for tony: 

5. Run puppet agent to pull latest configuration from puppet server

[root@stapp01 ~]# puppet agent -tv
		Info: Using configured environment 'production'
		Info: Retrieving pluginfacts
		Info: Retrieving plugin
		Info: Retrieving locales
		Info: Caching catalog for stapp01.stratos.xfusioncorp.com
		Info: Applying configuration version '1666854162'
		Notice: /Stage[main]/User_creator/User[ravi]/ensure: created
		Notice: Applied catalog in 0.06 seconds

6. Verify the new user created 

[root@stapp01 ~]# cat /etc/passwd |grep ravi
	ravi:x:1879:1879::/home/ravi:/bin/bash

--------------------------------------------------------------------------------------------------------------------------------
Task 98: 28/Oct/2022

Kubernetes Time Check Pod

The Nautilus DevOps team want to create a time check pod in a particular Kubernetes namespace and record the logs. This might be initially used only for testing purposes, but later can be implemented in an existing cluster. Please find more details below about the task and perform it.

    Create a pod called time-check in the datacenter namespace. This pod should run a container called time-check, container should use the busybox image with latest tag only and remember to mention tag i.e busybox:latest.

    Create a config map called time-config with the data TIME_FREQ=12 in the same namespace.

    The time-check container should run the command: while true; do date; sleep $TIME_FREQ;done and should write the result to the location /opt/dba/time/time-check.log. Remember you will also need to add an environmental variable TIME_FREQ in the container, which should pick value from the config map TIME_FREQ key.

    Create a volume log-volume and mount the same on /opt/dba/time within the container.

Note: The kubectl utility on jump_host has been configured to work with the kubernetes cluster.


1. Check kubectl utility config on jump server 

thor@jump_host ~$ kubectl get namespace
		NAME                 STATUS   AGE
		default              Active   115m
		kube-node-lease      Active   115m
		kube-public          Active   115m
		kube-system          Active   115m
		local-path-storage   Active   115m

thor@jump_host ~$ kubectl get pods
	No resources found in default namespace.

2. Create new namespace 

thor@jump_host ~$ kubectl create namespace datacenter
	namespace/datacenter created

thor@jump_host ~$ kubectl get namespace
		NAME                 STATUS   AGE
		datacenter           Active   4s
		default              Active   116m
		kube-node-lease      Active   116m
		kube-public          Active   116m
		kube-system          Active   116m
		local-path-storage   Active   115m

3. Create YAML file as per given requirements 

thor@jump_host ~$ vi /tmp/time_check.yaml
 
thor@jump_host ~$ cat /tmp/time_check.yaml 

		apiVersion: v1
		kind: Namespace
		metadata:
		  name: datacenter

		---
		apiVersion: v1
		kind: ConfigMap
		metadata:
		  name: time-config
		  namespace: datacenter
		data:
		    TIME_FREQ: "12"

		---    
		apiVersion: v1
		kind: Pod
		metadata:
		  name: time-check
		  namespace: datacenter
		spec:
		  containers:
		    - name: time-check
		      image: busybox:latest
		      command: [ "sh", "-c", "while true; do date; sleep $TIME_FREQ;done >> /opt/dba/time/time-check.log" ]
		      env:
		        - name: TIME_FREQ
		          valueFrom:
		            configMapKeyRef:
		              name: time-config
		              key: TIME_FREQ
		      volumeMounts:
		      - name: log-volume
		        mountPath: /opt/dba/time
		  volumes:
		    - name: log-volume
		      emptyDir : {}
		  restartPolicy: Never

4. Create Pod using the YAML file

thor@jump_host ~$ kubectl create -f  /tmp/time_check.yaml 
		configmap/time-config created
		pod/time-check created
		Error from server (AlreadyExists): error when creating "/tmp/time_check.yaml": namespaces "datacenter" already exists

5. Verify the pod running status 

thor@jump_host ~$ kubectl get pods -n datacenter
		NAME         READY   STATUS    RESTARTS   AGE
		time-check   1/1     Running   0          29s

thor@jump_host ~$ kubectl get pods -n datacenter
		NAME         READY   STATUS    RESTARTS   AGE
		time-check   1/1     Running   0          32s

--------------------------------------------------------------------------------------------------------------------------------
Task 99: 04/Nov/2022

Deploy MySQL on Kubernetes



A new MySQL server needs to be deployed on Kubernetes cluster. The Nautilus DevOps team was working on to gather the requirements. Recently they were able to finalize the requirements and shared them with the team members to start working on it. Below you can find the details:

1.) Create a PersistentVolume mysql-pv, its capacity should be 250Mi, set other parameters as per your preference.

2.) Create a PersistentVolumeClaim to request this PersistentVolume storage. Name it as mysql-pv-claim and request a 250Mi of storage. Set other parameters as per your preference.

3.) Create a deployment named mysql-deployment, use any mysql image as per your preference. Mount the PersistentVolume at mount path /var/lib/mysql.

4.) Create a NodePort type service named mysql and set nodePort to 30007.

5.) Create a secret named mysql-root-pass having a key pair value, where key is password and its value is YUIidhb667, create another secret named mysql-user-pass having some key pair values, where frist key is username and its value is kodekloud_pop, second key is password and value is GyQkFRVNr3, create one more secret named mysql-db-url, key name is database and value is kodekloud_db7

6.) Define some Environment variables within the container:

a) name: MYSQL_ROOT_PASSWORD, should pick value from secretKeyRef name: mysql-root-pass and key: password

b) name: MYSQL_DATABASE, should pick value from secretKeyRef name: mysql-db-url and key: database

c) name: MYSQL_USER, should pick value from secretKeyRef name: mysql-user-pass key key: username

d) name: MYSQL_PASSWORD, should pick value from secretKeyRef name: mysql-user-pass and key: password

Note: The kubectl utility on jump_host has been configured to work with the kubernetes cluster.


1. Check Kubectl service status and config

thor@jump_host ~$ kubectl get all
		NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
		service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   38m

thor@jump_host ~$ kubectl get service
		NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
		kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   38m

thor@jump_host ~$ kubectl get pv
		No resources found

thor@jump_host ~$ kubectl get pvc
		No resources found in default namespace.

2. Create Kubectl Secrets as per given task

thor@jump_host ~$ kubectl create secret generic mysql-root-pass --from-literal=password=YUIidhb667
		secret/mysql-root-pass created
 
thor@jump_host ~$ kubectl create secret generic mysql-user-pass --from-literal=username=kodekloud_pop --from-literal=password=GyQkFRVNr3
		secret/mysql-user-pass created

thor@jump_host ~$ kubectl create secret generic mysql-db-url --from-literal=database=kodekloud_db7
		secret/mysql-db-url created

3. Verify Secrets creation

thor@jump_host ~$ kubectl get all
		NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
		service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   40m

thor@jump_host ~$ kubectl get secrets
		NAME                  TYPE                                  DATA   AGE
		default-token-d62nx   kubernetes.io/service-account-token   3      40m
		mysql-db-url          Opaque                                1      16s
		mysql-root-pass       Opaque                                1      47s
		mysql-user-pass       Opaque                                2      28s

4. Create YAML file as per requirement
 
thor@jump_host ~$ vi /tmp/mysql_deploy.yaml
 
thor@jump_host ~$ cat /tmp/mysql_deploy.yaml 
		---                                                                                           
		apiVersion: v1                                                                                
		kind: PersistentVolume                                                                        
		metadata:                                                                                     
		  name: mysql-pv                                                                              
		spec:                                                                                         
		  capacity:                                                                                   
		    storage: 250Mi     
		  accessModes:                                                                                
		    - ReadWriteOnce                                                                           
		  hostPath:                                                                                   
		    path: "/var/lib/mysql"                                                                    
		---                                                                                           
		apiVersion: v1                                                                                
		kind: PersistentVolumeClaim                                                                   
		metadata:                                                                                     
		  name: mysql-pv-claim                                                                        
		spec:                                                                                         
		  accessModes:                                                                                
		    - ReadWriteOnce                                                                           
		  resources:                                                                                  
		    requests:                                                                                 
		      storage: 250Mi                                                                          
		---
		apiVersion: v1
		kind: Service
		metadata:
		  name: mysql
		spec:
		  type: NodePort
		  selector:
		    app: mysql
		  ports:
		    - port: 3306
		      targetPort: 3306
		      nodePort: 30007
		---       
		apiVersion: apps/v1
		kind: Deployment
		metadata:
		  name: mysql-deployment
		  labels:
		    app: mysql
		spec:
		  replicas: 1
		  selector:
		    matchLabels:
		      app: mysql
		  template:
		    metadata:
		      labels:
		        app: mysql
		    spec:
		      volumes:
		      - name: mysql-pv
		        persistentVolumeClaim:
		          claimName: mysql-pv-claim
		      containers:
		      - name: mysql
		        image: mysql:latest
		        env:
		        - name: MYSQL_ROOT_PASSWORD
		          valueFrom:
		            secretKeyRef:
		              name: mysql-root-pass
		              key: password
		        - name: MYSQL_DATABASE
		          valueFrom:
		            secretKeyRef:
		              name: mysql-db-url
		              key: database
		        - name: MYSQL_USER
		          valueFrom:
		            secretKeyRef:
		              name: mysql-user-pass
		              key: username
		        - name: MYSQL_PASSWORD
		          valueFrom:
		            secretKeyRef:
		              name: mysql-user-pass
		              key: password
		        volumeMounts:
		        - name: mysql-pv
		          mountPath: /var/lib/mysql
		        ports:
		        - containerPort: 3306
		          name: mysql


5. Create Pods  using the YAML file

thor@jump_host ~$ kubectl create -f  /tmp/mysql_deploy.yaml 
		persistentvolume/mysql-pv created
		persistentvolumeclaim/mysql-pv-claim created
		service/mysql created
		deployment.apps/mysql-deployment created

6. Verify the components created 

thor@jump_host ~$ kubectl get pv
		NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                    STORAGECLASS   REASON   AGE
		mysql-pv                                   250Mi      RWO            Retain           Available                                                    13s
		pvc-c497c610-d100-4616-b073-56b04050cfa3   250Mi      RWO            Delete           Bound       default/mysql-pv-claim   standard                9s

thor@jump_host ~$ kubectl get pvc
		NAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
		mysql-pv-claim   Bound    pvc-c497c610-d100-4616-b073-56b04050cfa3   250Mi      RWO            standard       19s

7. Wait for Pods to get into running status and check the ENV for MYSQL env variables in the pod created

thor@jump_host ~$ kubectl get all
		NAME                                    READY   STATUS              RESTARTS   AGE
		pod/mysql-deployment-6ccf56667c-dmrw5   0/1     ContainerCreating   0          32s

		NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
		service/kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP          42m
		service/mysql        NodePort    10.96.210.211   <none>        3306:30007/TCP   32s

		NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
		deployment.apps/mysql-deployment   0/1     1            0           32s

		NAME                                          DESIRED   CURRENT   READY   AGE
		replicaset.apps/mysql-deployment-6ccf56667c   1         1         0       32s

thor@jump_host ~$ kubectl get all
		NAME                                    READY   STATUS    RESTARTS   AGE
		pod/mysql-deployment-6ccf56667c-dmrw5   1/1     Running   0          45s

		NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
		service/kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP          42m
		service/mysql        NodePort    10.96.210.211   <none>        3306:30007/TCP   45s

		NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
		deployment.apps/mysql-deployment   1/1     1            1           45s

		NAME                                          DESIRED   CURRENT   READY   AGE
		replicaset.apps/mysql-deployment-6ccf56667c   1         1         1       45s


thor@jump_host ~$ kubectl exec -it mysql-deployment-6ccf56667c-dmrw5 -- /bin/bash

bash-4.4# printenv
		MYSQL_PASSWORD=GyQkFRVNr3
		MYSQL_PORT_3306_TCP_PROTO=tcp
		HOSTNAME=mysql-deployment-6ccf56667c-dmrw5
		MYSQL_DATABASE=kodekloud_db7
		KUBERNETES_PORT_443_TCP_PROTO=tcp
		MYSQL_SERVICE_PORT=3306
		KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
		MYSQL_ROOT_PASSWORD=YUIidhb667
		MYSQL_PORT=tcp://10.96.210.211:3306
		KUBERNETES_PORT=tcp://10.96.0.1:443
		MYSQL_PORT_3306_TCP=tcp://10.96.210.211:3306
		PWD=/
		HOME=/root
		MYSQL_MAJOR=8.0
		GOSU_VERSION=1.14
		MYSQL_USER=kodekloud_pop
		MYSQL_PORT_3306_TCP_PORT=3306
		KUBERNETES_SERVICE_PORT_HTTPS=443
		MYSQL_PORT_3306_TCP_ADDR=10.96.210.211
		KUBERNETES_PORT_443_TCP_PORT=443
		MYSQL_VERSION=8.0.31-1.el8
		KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443
		TERM=xterm
		SHLVL=1
		KUBERNETES_SERVICE_PORT=443
		PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
		KUBERNETES_SERVICE_HOST=10.96.0.1
		MYSQL_SHELL_VERSION=8.0.31-1.el8
		MYSQL_SERVICE_HOST=10.96.210.211
		_=/usr/bin/printenv
bash-4.4# 

--------------------------------------------------------------------------------------------------------------------------------
Task 100: 05/Nov/2022

Git Install and Create Bare Repository

The Nautilus development team shared requirements with the DevOps team regarding new application development.specifically, they want to set up a Git repository for that project. Create a Git repository on Storage server in Stratos DC as per details given below:

    Install git package using yum on Storage server.

    After that create a bare repository /opt/news.git (make sure to use exact name).


1. Login on storage server and switch to root user

thor@jump_host ~$ ssh natasha@ststor01
		The authenticity of host 'ststor01 (172.16.238.15)' can't be established.
		ECDSA key fingerprint is SHA256:IEbMfpjmum1MkMYwoKYJ6cm72/aRpYpB9G787u7jPMM.
		ECDSA key fingerprint is MD5:55:d5:fc:19:3e:f2:bb:47:77:9d:7d:a7:ea:cc:e7:61.
		Are you sure you want to continue connecting (yes/no)? yes
		Warning: Permanently added 'ststor01,172.16.238.15' (ECDSA) to the list of known hosts.
		natasha@ststor01's password: 

[natasha@ststor01 ~]$ sudo su -

		We trust you have received the usual lecture from the local System
		Administrator. It usually boils down to these three things:

		    #1) Respect the privacy of others.
		    #2) Think before you type.
		    #3) With great power comes great responsibility.

		[sudo] password for natasha: 

2. Install git package using yum 

[root@ststor01 ~]# rpm -qa |grep git

[root@ststor01 ~]# yum install -y git
		Loaded plugins: fastestmirror, ovl
		Determining fastest mirrors
		 * base: ftpmirror.your.org
		 * extras: mirror.genesishosting.com
		 * updates: tx-mirror.tier.net
		base                                                                                                                  | 3.6 kB  00:00:00     
		extras                                                                                                                | 2.9 kB  00:00:00     
		updates                                                                                                               | 2.9 kB  00:00:00     
		(1/4): base/7/x86_64/group_gz                                                                                         | 153 kB  00:00:00     
		(2/4): extras/7/x86_64/primary_db                                                                                     | 249 kB  00:00:00     
		(3/4): base/7/x86_64/primary_db                                                                                       | 6.1 MB  00:00:00     
		(4/4): updates/7/x86_64/primary_db                                                                                    |  17 MB  00:00:00     
		Resolving Dependencies
		--> Running transaction check
		---> Package git.x86_64 0:1.8.3.1-23.el7_8 will be installed
		--> Processing Dependency: perl-Git = 1.8.3.1-23.el7_8 for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl >= 5.008 for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: rsync for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(warnings) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(vars) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(strict) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(lib) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(Term::ReadKey) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(Git) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(Getopt::Long) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(File::stat) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(File::Temp) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(File::Spec) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(File::Path) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(File::Find) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(File::Copy) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(File::Basename) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(Exporter) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: perl(Error) for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: openssh-clients for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: less for package: git-1.8.3.1-23.el7_8.x86_64
		--> Processing Dependency: /usr/bin/perl for package: git-1.8.3.1-23.el7_8.x86_64
		--> Running transaction check
		---> Package less.x86_64 0:458-9.el7 will be installed
		--> Processing Dependency: groff-base for package: less-458-9.el7.x86_64
		---> Package openssh-clients.x86_64 0:7.4p1-22.el7_9 will be installed
		--> Processing Dependency: openssh = 7.4p1-22.el7_9 for package: openssh-clients-7.4p1-22.el7_9.x86_64
		--> Processing Dependency: libedit.so.0()(64bit) for package: openssh-clients-7.4p1-22.el7_9.x86_64
		---> Package perl.x86_64 4:5.16.3-299.el7_9 will be installed
		--> Processing Dependency: perl-libs = 4:5.16.3-299.el7_9 for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(Socket) >= 1.3 for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(Scalar::Util) >= 1.10 for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl-macros for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl-libs for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(threads::shared) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(threads) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(constant) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(Time::Local) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(Time::HiRes) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(Storable) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(Socket) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(Scalar::Util) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(Pod::Simple::XHTML) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(Pod::Simple::Search) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(Filter::Util::Call) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: perl(Carp) for package: 4:perl-5.16.3-299.el7_9.x86_64
		--> Processing Dependency: libperl.so()(64bit) for package: 4:perl-5.16.3-299.el7_9.x86_64
		---> Package perl-Error.noarch 1:0.17020-2.el7 will be installed
		---> Package perl-Exporter.noarch 0:5.68-3.el7 will be installed
		---> Package perl-File-Path.noarch 0:2.09-2.el7 will be installed
		---> Package perl-File-Temp.noarch 0:0.23.01-3.el7 will be installed
		---> Package perl-Getopt-Long.noarch 0:2.40-3.el7 will be installed
		--> Processing Dependency: perl(Pod::Usage) >= 1.14 for package: perl-Getopt-Long-2.40-3.el7.noarch
		--> Processing Dependency: perl(Text::ParseWords) for package: perl-Getopt-Long-2.40-3.el7.noarch
		---> Package perl-Git.noarch 0:1.8.3.1-23.el7_8 will be installed
		---> Package perl-PathTools.x86_64 0:3.40-5.el7 will be installed
		---> Package perl-TermReadKey.x86_64 0:2.30-20.el7 will be installed
		---> Package rsync.x86_64 0:3.1.2-11.el7_9 will be installed
		--> Running transaction check
		---> Package groff-base.x86_64 0:1.22.2-8.el7 will be installed
		---> Package libedit.x86_64 0:3.0-12.20121213cvs.el7 will be installed
		---> Package openssh.x86_64 0:7.4p1-21.el7 will be updated
		--> Processing Dependency: openssh = 7.4p1-21.el7 for package: openssh-server-7.4p1-21.el7.x86_64
		---> Package openssh.x86_64 0:7.4p1-22.el7_9 will be an update
		---> Package perl-Carp.noarch 0:1.26-244.el7 will be installed
		---> Package perl-Filter.x86_64 0:1.49-3.el7 will be installed
		---> Package perl-Pod-Simple.noarch 1:3.28-4.el7 will be installed
		--> Processing Dependency: perl(Pod::Escapes) >= 1.04 for package: 1:perl-Pod-Simple-3.28-4.el7.noarch
		--> Processing Dependency: perl(Encode) for package: 1:perl-Pod-Simple-3.28-4.el7.noarch
		---> Package perl-Pod-Usage.noarch 0:1.63-3.el7 will be installed
		--> Processing Dependency: perl(Pod::Text) >= 3.15 for package: perl-Pod-Usage-1.63-3.el7.noarch
		--> Processing Dependency: perl-Pod-Perldoc for package: perl-Pod-Usage-1.63-3.el7.noarch
		---> Package perl-Scalar-List-Utils.x86_64 0:1.27-248.el7 will be installed
		---> Package perl-Socket.x86_64 0:2.010-5.el7 will be installed
		---> Package perl-Storable.x86_64 0:2.45-3.el7 will be installed
		---> Package perl-Text-ParseWords.noarch 0:3.29-4.el7 will be installed
		---> Package perl-Time-HiRes.x86_64 4:1.9725-3.el7 will be installed
		---> Package perl-Time-Local.noarch 0:1.2300-2.el7 will be installed
		---> Package perl-constant.noarch 0:1.27-2.el7 will be installed
		---> Package perl-libs.x86_64 4:5.16.3-299.el7_9 will be installed
		---> Package perl-macros.x86_64 4:5.16.3-299.el7_9 will be installed
		---> Package perl-threads.x86_64 0:1.87-4.el7 will be installed
		---> Package perl-threads-shared.x86_64 0:1.43-6.el7 will be installed
		--> Running transaction check
		---> Package openssh-server.x86_64 0:7.4p1-21.el7 will be updated
		---> Package openssh-server.x86_64 0:7.4p1-22.el7_9 will be an update
		---> Package perl-Encode.x86_64 0:2.51-7.el7 will be installed
		---> Package perl-Pod-Escapes.noarch 1:1.04-299.el7_9 will be installed
		---> Package perl-Pod-Perldoc.noarch 0:3.20-4.el7 will be installed
		--> Processing Dependency: perl(parent) for package: perl-Pod-Perldoc-3.20-4.el7.noarch
		--> Processing Dependency: perl(HTTP::Tiny) for package: perl-Pod-Perldoc-3.20-4.el7.noarch
		---> Package perl-podlators.noarch 0:2.5.1-3.el7 will be installed
		--> Running transaction check
		---> Package perl-HTTP-Tiny.noarch 0:0.033-3.el7 will be installed
		---> Package perl-parent.noarch 1:0.225-244.el7 will be installed
		--> Finished Dependency Resolution

		Dependencies Resolved

		=============================================================================================================================================
		 Package                                  Arch                     Version                                   Repository                 Size
		=============================================================================================================================================
		Installing:
		 git                                      x86_64                   1.8.3.1-23.el7_8                          base                      4.4 M
		Installing for dependencies:
		 groff-base                               x86_64                   1.22.2-8.el7                              base                      942 k
		 less                                     x86_64                   458-9.el7                                 base                      120 k
		 libedit                                  x86_64                   3.0-12.20121213cvs.el7                    base                       92 k
		 openssh-clients                          x86_64                   7.4p1-22.el7_9                            updates                   655 k
		 perl                                     x86_64                   4:5.16.3-299.el7_9                        updates                   8.0 M
		 perl-Carp                                noarch                   1.26-244.el7                              base                       19 k
		 perl-Encode                              x86_64                   2.51-7.el7                                base                      1.5 M
		 perl-Error                               noarch                   1:0.17020-2.el7                           base                       32 k
		 perl-Exporter                            noarch                   5.68-3.el7                                base                       28 k
		 perl-File-Path                           noarch                   2.09-2.el7                                base                       26 k
		 perl-File-Temp                           noarch                   0.23.01-3.el7                             base                       56 k
		 perl-Filter                              x86_64                   1.49-3.el7                                base                       76 k
		 perl-Getopt-Long                         noarch                   2.40-3.el7                                base                       56 k
		 perl-Git                                 noarch                   1.8.3.1-23.el7_8                          base                       56 k
		 perl-HTTP-Tiny                           noarch                   0.033-3.el7                               base                       38 k
		 perl-PathTools                           x86_64                   3.40-5.el7                                base                       82 k
		 perl-Pod-Escapes                         noarch                   1:1.04-299.el7_9                          updates                    52 k
		 perl-Pod-Perldoc                         noarch                   3.20-4.el7                                base                       87 k
		 perl-Pod-Simple                          noarch                   1:3.28-4.el7                              base                      216 k
		 perl-Pod-Usage                           noarch                   1.63-3.el7                                base                       27 k
		 perl-Scalar-List-Utils                   x86_64                   1.27-248.el7                              base                       36 k
		 perl-Socket                              x86_64                   2.010-5.el7                               base                       49 k
		 perl-Storable                            x86_64                   2.45-3.el7                                base                       77 k
		 perl-TermReadKey                         x86_64                   2.30-20.el7                               base                       31 k
		 perl-Text-ParseWords                     noarch                   3.29-4.el7                                base                       14 k
		 perl-Time-HiRes                          x86_64                   4:1.9725-3.el7                            base                       45 k
		 perl-Time-Local                          noarch                   1.2300-2.el7                              base                       24 k
		 perl-constant                            noarch                   1.27-2.el7                                base                       19 k
		 perl-libs                                x86_64                   4:5.16.3-299.el7_9                        updates                   690 k
		 perl-macros                              x86_64                   4:5.16.3-299.el7_9                        updates                    44 k
		 perl-parent                              noarch                   1:0.225-244.el7                           base                       12 k
		 perl-podlators                           noarch                   2.5.1-3.el7                               base                      112 k
		 perl-threads                             x86_64                   1.87-4.el7                                base                       49 k
		 perl-threads-shared                      x86_64                   1.43-6.el7                                base                       39 k
		 rsync                                    x86_64                   3.1.2-11.el7_9                            updates                   408 k
		Updating for dependencies:
		 openssh                                  x86_64                   7.4p1-22.el7_9                            updates                   510 k
		 openssh-server                           x86_64                   7.4p1-22.el7_9                            updates                   459 k

		Transaction Summary
		=============================================================================================================================================
		Install  1 Package  (+35 Dependent packages)
		Upgrade             (  2 Dependent packages)

		Total download size: 19 M
		Downloading packages:
		Delta RPMs disabled because /usr/bin/applydeltarpm not installed.
		(1/38): groff-base-1.22.2-8.el7.x86_64.rpm                                                                            | 942 kB  00:00:00     
		(2/38): git-1.8.3.1-23.el7_8.x86_64.rpm                                                                               | 4.4 MB  00:00:00     
		(3/38): less-458-9.el7.x86_64.rpm                                                                                     | 120 kB  00:00:00     
		(4/38): libedit-3.0-12.20121213cvs.el7.x86_64.rpm                                                                     |  92 kB  00:00:00     
		(5/38): openssh-7.4p1-22.el7_9.x86_64.rpm                                                                             | 510 kB  00:00:00     
		(6/38): openssh-clients-7.4p1-22.el7_9.x86_64.rpm                                                                     | 655 kB  00:00:00     
		(7/38): openssh-server-7.4p1-22.el7_9.x86_64.rpm                                                                      | 459 kB  00:00:00     
		(8/38): perl-Carp-1.26-244.el7.noarch.rpm                                                                             |  19 kB  00:00:00     
		(9/38): perl-Error-0.17020-2.el7.noarch.rpm                                                                           |  32 kB  00:00:00     
		(10/38): perl-Exporter-5.68-3.el7.noarch.rpm                                                                          |  28 kB  00:00:00     
		(11/38): perl-File-Path-2.09-2.el7.noarch.rpm                                                                         |  26 kB  00:00:00     
		(12/38): perl-File-Temp-0.23.01-3.el7.noarch.rpm                                                                      |  56 kB  00:00:00     
		(13/38): perl-Filter-1.49-3.el7.x86_64.rpm                                                                            |  76 kB  00:00:00     
		(14/38): perl-Getopt-Long-2.40-3.el7.noarch.rpm                                                                       |  56 kB  00:00:00     
		(15/38): perl-Git-1.8.3.1-23.el7_8.noarch.rpm                                                                         |  56 kB  00:00:00     
		(16/38): perl-HTTP-Tiny-0.033-3.el7.noarch.rpm                                                                        |  38 kB  00:00:00     
		(17/38): perl-PathTools-3.40-5.el7.x86_64.rpm                                                                         |  82 kB  00:00:00     
		(18/38): perl-Pod-Escapes-1.04-299.el7_9.noarch.rpm                                                                   |  52 kB  00:00:00     
		(19/38): perl-Encode-2.51-7.el7.x86_64.rpm                                                                            | 1.5 MB  00:00:00     
		(20/38): perl-Pod-Perldoc-3.20-4.el7.noarch.rpm                                                                       |  87 kB  00:00:00     
		(21/38): perl-5.16.3-299.el7_9.x86_64.rpm                                                                             | 8.0 MB  00:00:00     
		(22/38): perl-Pod-Usage-1.63-3.el7.noarch.rpm                                                                         |  27 kB  00:00:00     
		(23/38): perl-Pod-Simple-3.28-4.el7.noarch.rpm                                                                        | 216 kB  00:00:00     
		(24/38): perl-Scalar-List-Utils-1.27-248.el7.x86_64.rpm                                                               |  36 kB  00:00:00     
		(25/38): perl-Storable-2.45-3.el7.x86_64.rpm                                                                          |  77 kB  00:00:00     
		(26/38): perl-TermReadKey-2.30-20.el7.x86_64.rpm                                                                      |  31 kB  00:00:00     
		(27/38): perl-Text-ParseWords-3.29-4.el7.noarch.rpm                                                                   |  14 kB  00:00:00     
		(28/38): perl-Time-HiRes-1.9725-3.el7.x86_64.rpm                                                                      |  45 kB  00:00:00     
		(29/38): perl-Time-Local-1.2300-2.el7.noarch.rpm                                                                      |  24 kB  00:00:00     
		(30/38): perl-Socket-2.010-5.el7.x86_64.rpm                                                                           |  49 kB  00:00:00     
		(31/38): perl-constant-1.27-2.el7.noarch.rpm                                                                          |  19 kB  00:00:00     
		(32/38): perl-parent-0.225-244.el7.noarch.rpm                                                                         |  12 kB  00:00:00     
		(33/38): perl-podlators-2.5.1-3.el7.noarch.rpm                                                                        | 112 kB  00:00:00     
		(34/38): perl-libs-5.16.3-299.el7_9.x86_64.rpm                                                                        | 690 kB  00:00:00     
		(35/38): perl-threads-shared-1.43-6.el7.x86_64.rpm                                                                    |  39 kB  00:00:00     
		(36/38): perl-threads-1.87-4.el7.x86_64.rpm                                                                           |  49 kB  00:00:00     
		(37/38): rsync-3.1.2-11.el7_9.x86_64.rpm                                                                              | 408 kB  00:00:00     
		(38/38): perl-macros-5.16.3-299.el7_9.x86_64.rpm                                                                      |  44 kB  00:00:00     
		---------------------------------------------------------------------------------------------------------------------------------------------
		Total                                                                                                         18 MB/s |  19 MB  00:00:01     
		Running transaction check
		Running transaction test
		Transaction test succeeded
		Running transaction
		  Installing : groff-base-1.22.2-8.el7.x86_64                                                                                           1/40 
		  Updating   : openssh-7.4p1-22.el7_9.x86_64                                                                                            2/40 
		  Installing : 1:perl-parent-0.225-244.el7.noarch                                                                                       3/40 
		  Installing : perl-HTTP-Tiny-0.033-3.el7.noarch                                                                                        4/40 
		  Installing : perl-podlators-2.5.1-3.el7.noarch                                                                                        5/40 
		  Installing : perl-Pod-Perldoc-3.20-4.el7.noarch                                                                                       6/40 
		  Installing : 1:perl-Pod-Escapes-1.04-299.el7_9.noarch                                                                                 7/40 
		  Installing : perl-Encode-2.51-7.el7.x86_64                                                                                            8/40 
		  Installing : perl-Text-ParseWords-3.29-4.el7.noarch                                                                                   9/40 
		  Installing : perl-Pod-Usage-1.63-3.el7.noarch                                                                                        10/40 
		  Installing : 4:perl-macros-5.16.3-299.el7_9.x86_64                                                                                   11/40 
		  Installing : 4:perl-Time-HiRes-1.9725-3.el7.x86_64                                                                                   12/40 
		  Installing : perl-Exporter-5.68-3.el7.noarch                                                                                         13/40 
		  Installing : perl-constant-1.27-2.el7.noarch                                                                                         14/40 
		  Installing : perl-Socket-2.010-5.el7.x86_64                                                                                          15/40 
		  Installing : perl-Time-Local-1.2300-2.el7.noarch                                                                                     16/40 
		  Installing : perl-Carp-1.26-244.el7.noarch                                                                                           17/40 
		  Installing : perl-Storable-2.45-3.el7.x86_64                                                                                         18/40 
		  Installing : perl-PathTools-3.40-5.el7.x86_64                                                                                        19/40 
		  Installing : perl-Scalar-List-Utils-1.27-248.el7.x86_64                                                                              20/40 
		  Installing : 1:perl-Pod-Simple-3.28-4.el7.noarch                                                                                     21/40 
		  Installing : perl-File-Temp-0.23.01-3.el7.noarch                                                                                     22/40 
		  Installing : perl-File-Path-2.09-2.el7.noarch                                                                                        23/40 
		  Installing : perl-threads-shared-1.43-6.el7.x86_64                                                                                   24/40 
		  Installing : perl-threads-1.87-4.el7.x86_64                                                                                          25/40 
		  Installing : perl-Filter-1.49-3.el7.x86_64                                                                                           26/40 
		  Installing : 4:perl-libs-5.16.3-299.el7_9.x86_64                                                                                     27/40 
		  Installing : perl-Getopt-Long-2.40-3.el7.noarch                                                                                      28/40 
		  Installing : 4:perl-5.16.3-299.el7_9.x86_64                                                                                          29/40 
		  Installing : 1:perl-Error-0.17020-2.el7.noarch                                                                                       30/40 
		  Installing : perl-TermReadKey-2.30-20.el7.x86_64                                                                                     31/40 
		  Installing : less-458-9.el7.x86_64                                                                                                   32/40 
		  Installing : libedit-3.0-12.20121213cvs.el7.x86_64                                                                                   33/40 
		  Installing : openssh-clients-7.4p1-22.el7_9.x86_64                                                                                   34/40 
		  Installing : rsync-3.1.2-11.el7_9.x86_64                                                                                             35/40 
		  Installing : perl-Git-1.8.3.1-23.el7_8.noarch                                                                                        36/40 
		  Installing : git-1.8.3.1-23.el7_8.x86_64                                                                                             37/40 
		  Updating   : openssh-server-7.4p1-22.el7_9.x86_64                                                                                    38/40 
		  Cleanup    : openssh-server-7.4p1-21.el7.x86_64                                                                                      39/40 
		  Cleanup    : openssh-7.4p1-21.el7.x86_64                                                                                             40/40 
		  Verifying  : perl-HTTP-Tiny-0.033-3.el7.noarch                                                                                        1/40 
		  Verifying  : perl-threads-shared-1.43-6.el7.x86_64                                                                                    2/40 
		  Verifying  : 4:perl-Time-HiRes-1.9725-3.el7.x86_64                                                                                    3/40 
		  Verifying  : openssh-clients-7.4p1-22.el7_9.x86_64                                                                                    4/40 
		  Verifying  : perl-Exporter-5.68-3.el7.noarch                                                                                          5/40 
		  Verifying  : perl-constant-1.27-2.el7.noarch                                                                                          6/40 
		  Verifying  : perl-PathTools-3.40-5.el7.x86_64                                                                                         7/40 
		  Verifying  : openssh-7.4p1-22.el7_9.x86_64                                                                                            8/40 
		  Verifying  : 4:perl-macros-5.16.3-299.el7_9.x86_64                                                                                    9/40 
		  Verifying  : git-1.8.3.1-23.el7_8.x86_64                                                                                             10/40 
		  Verifying  : 1:perl-parent-0.225-244.el7.noarch                                                                                      11/40 
		  Verifying  : perl-Socket-2.010-5.el7.x86_64                                                                                          12/40 
		  Verifying  : rsync-3.1.2-11.el7_9.x86_64                                                                                             13/40 
		  Verifying  : perl-TermReadKey-2.30-20.el7.x86_64                                                                                     14/40 
		  Verifying  : groff-base-1.22.2-8.el7.x86_64                                                                                          15/40 
		  Verifying  : perl-File-Temp-0.23.01-3.el7.noarch                                                                                     16/40 
		  Verifying  : 1:perl-Pod-Simple-3.28-4.el7.noarch                                                                                     17/40 
		  Verifying  : perl-Time-Local-1.2300-2.el7.noarch                                                                                     18/40 
		  Verifying  : 1:perl-Pod-Escapes-1.04-299.el7_9.noarch                                                                                19/40 
		  Verifying  : perl-Git-1.8.3.1-23.el7_8.noarch                                                                                        20/40 
		  Verifying  : perl-Carp-1.26-244.el7.noarch                                                                                           21/40 
		  Verifying  : 1:perl-Error-0.17020-2.el7.noarch                                                                                       22/40 
		  Verifying  : perl-Storable-2.45-3.el7.x86_64                                                                                         23/40 
		  Verifying  : perl-Scalar-List-Utils-1.27-248.el7.x86_64                                                                              24/40 
		  Verifying  : perl-Pod-Usage-1.63-3.el7.noarch                                                                                        25/40 
		  Verifying  : perl-Encode-2.51-7.el7.x86_64                                                                                           26/40 
		  Verifying  : perl-Pod-Perldoc-3.20-4.el7.noarch                                                                                      27/40 
		  Verifying  : perl-podlators-2.5.1-3.el7.noarch                                                                                       28/40 
		  Verifying  : 4:perl-5.16.3-299.el7_9.x86_64                                                                                          29/40 
		  Verifying  : perl-File-Path-2.09-2.el7.noarch                                                                                        30/40 
		  Verifying  : libedit-3.0-12.20121213cvs.el7.x86_64                                                                                   31/40 
		  Verifying  : perl-threads-1.87-4.el7.x86_64                                                                                          32/40 
		  Verifying  : openssh-server-7.4p1-22.el7_9.x86_64                                                                                    33/40 
		  Verifying  : perl-Filter-1.49-3.el7.x86_64                                                                                           34/40 
		  Verifying  : perl-Getopt-Long-2.40-3.el7.noarch                                                                                      35/40 
		  Verifying  : perl-Text-ParseWords-3.29-4.el7.noarch                                                                                  36/40 
		  Verifying  : 4:perl-libs-5.16.3-299.el7_9.x86_64                                                                                     37/40 
		  Verifying  : less-458-9.el7.x86_64                                                                                                   38/40 
		  Verifying  : openssh-7.4p1-21.el7.x86_64                                                                                             39/40 
		  Verifying  : openssh-server-7.4p1-21.el7.x86_64                                                                                      40/40 

		Installed:
		  git.x86_64 0:1.8.3.1-23.el7_8                                                                                                              

		Dependency Installed:
		  groff-base.x86_64 0:1.22.2-8.el7             less.x86_64 0:458-9.el7                      libedit.x86_64 0:3.0-12.20121213cvs.el7         
		  openssh-clients.x86_64 0:7.4p1-22.el7_9      perl.x86_64 4:5.16.3-299.el7_9               perl-Carp.noarch 0:1.26-244.el7                 
		  perl-Encode.x86_64 0:2.51-7.el7              perl-Error.noarch 1:0.17020-2.el7            perl-Exporter.noarch 0:5.68-3.el7               
		  perl-File-Path.noarch 0:2.09-2.el7           perl-File-Temp.noarch 0:0.23.01-3.el7        perl-Filter.x86_64 0:1.49-3.el7                 
		  perl-Getopt-Long.noarch 0:2.40-3.el7         perl-Git.noarch 0:1.8.3.1-23.el7_8           perl-HTTP-Tiny.noarch 0:0.033-3.el7             
		  perl-PathTools.x86_64 0:3.40-5.el7           perl-Pod-Escapes.noarch 1:1.04-299.el7_9     perl-Pod-Perldoc.noarch 0:3.20-4.el7            
		  perl-Pod-Simple.noarch 1:3.28-4.el7          perl-Pod-Usage.noarch 0:1.63-3.el7           perl-Scalar-List-Utils.x86_64 0:1.27-248.el7    
		  perl-Socket.x86_64 0:2.010-5.el7             perl-Storable.x86_64 0:2.45-3.el7            perl-TermReadKey.x86_64 0:2.30-20.el7           
		  perl-Text-ParseWords.noarch 0:3.29-4.el7     perl-Time-HiRes.x86_64 4:1.9725-3.el7        perl-Time-Local.noarch 0:1.2300-2.el7           
		  perl-constant.noarch 0:1.27-2.el7            perl-libs.x86_64 4:5.16.3-299.el7_9          perl-macros.x86_64 4:5.16.3-299.el7_9           
		  perl-parent.noarch 1:0.225-244.el7           perl-podlators.noarch 0:2.5.1-3.el7          perl-threads.x86_64 0:1.87-4.el7                
		  perl-threads-shared.x86_64 0:1.43-6.el7      rsync.x86_64 0:3.1.2-11.el7_9               

		Dependency Updated:
		  openssh.x86_64 0:7.4p1-22.el7_9                                   openssh-server.x86_64 0:7.4p1-22.el7_9                                  

		Complete!

[root@ststor01 ~]# rpm -qa |grep git
		git-1.8.3.1-23.el7_8.x86_64

3. Go to mentioned folder and init a Bare git repo 

[root@ststor01 ~]# cd /opt

[root@ststor01 opt]# ls -ahl
		total 8.0K
		drwxr-xr-x 1 root root 4.0K Apr 11  2018 .
		drwxr-xr-x 1 root root 4.0K Nov  5 15:29 ..
 
[root@ststor01 opt]# git init --bare news.git
		Initialized empty Git repository in /opt/news.git/

[root@ststor01 opt]# ls -ahl
		total 12K
		drwxr-xr-x 1 root root 4.0K Nov  5 15:32 .
		drwxr-xr-x 1 root root 4.0K Nov  5 15:29 ..
		drwxr-xr-x 7 root root 4.0K Nov  5 15:32 news.git

[root@ststor01 opt]# cd news.git/

[root@ststor01 news.git]# git status
		fatal: This operation must be run in a work tree

[root@ststor01 news.git]# ls -ahl
		total 40K
		drwxr-xr-x 7 root root 4.0K Nov  5 15:32 .
		drwxr-xr-x 1 root root 4.0K Nov  5 15:32 ..
		drwxr-xr-x 2 root root 4.0K Nov  5 15:32 branches
		-rw-r--r-- 1 root root   66 Nov  5 15:32 config
		-rw-r--r-- 1 root root   73 Nov  5 15:32 description
		-rw-r--r-- 1 root root   23 Nov  5 15:32 HEAD
		drwxr-xr-x 2 root root 4.0K Nov  5 15:32 hooks
		drwxr-xr-x 2 root root 4.0K Nov  5 15:32 info
		drwxr-xr-x 4 root root 4.0K Nov  5 15:32 objects
		drwxr-xr-x 4 root root 4.0K Nov  5 15:32 refs

[root@ststor01 news.git]# 

--------------------------------------------------------------------------------------------------------------------------------
Task 101: 16/Nov/2022

Deploy Nginx and Phpfpm on Kubernetes

The Nautilus Application Development team is planning to deploy one of the php-based application on Kubernetes cluster. As per discussion with DevOps team they have decided to use nginx and phpfpm. Additionally, they shared some custom configuration requirements. Below you can find more details. Please complete the task as per requirements mentioned below:

1) Create a service to expose this app, the service type must be NodePort, nodePort should be 30012.

2.) Create a config map nginx-config for nginx.conf as we want to add some custom settings for nginx.conf.

a) Change default port 80 to 8091 in nginx.conf.

b) Change default document root /usr/share/nginx to /var/www/html in nginx.conf.

c) Update directory index to index index.html index.htm index.php in nginx.conf.

3.) Create a pod named nginx-phpfpm .

b) Create a shared volume shared-files that will be used by both containers (nginx and phpfpm) also it should be a emptyDir volume.

c) Map the ConfigMap we declared above as a volume for nginx container. Name the volume as nginx-config-volume, mount path should be /etc/nginx/nginx.conf and subPath should be nginx.conf

d) Nginx container should be named as nginx-container and it should use nginx:latest image. PhpFPM container should be named as php-fpm-container and it should use php:7.0-fpm image.

e) The shared volume shared-files should be mounted at /var/www/html location in both containers. Copy /opt/index.php from jump host to the nginx document root inside nginx container, once done you can access the app using App button on the top bar.

Before clicking on finish button always make sure to check if all pods are in running state.

You can use any labels as per your choice.

Note: The kubectl utility on jump_host has been configured to work with the kubernetes cluster.

1. Check kubectl utility and current configuration

thor@jump_host ~$ kubectl get all
		NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
		service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   5h9m

2. Create the config YAML file as per the requirements 

thor@jump_host ~$ vi /tmp/nginx_phpfpm.yml

thor@jump_host ~$ cat /tmp/nginx_phpfpm.yml 
		#ConfigMap Configuration
		---
		apiVersion: v1
		kind: ConfigMap
		metadata:
		  name: nginx-config
		data:
		  nginx.conf: |
		    events {} 
		    http {
		      server {
		        listen 8091;
		        index index.html index.htm index.php;
		        root  /var/www/html;
		        location ~ \.php$ {
		          include fastcgi_params;
		          fastcgi_param REQUEST_METHOD $request_method;
		          fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
		          fastcgi_pass 127.0.0.1:9000;
		        }
		      }
		    }


		#Pod Configuration    
		---
		apiVersion: v1
		kind: Pod
		metadata:
		  name: nginx-phpfpm
		  labels:
		     app: nginx-phpfpm
		     tier: back-end
		spec:
		  volumes:
		    - name: shared-files
		      emptyDir: {}
		    - name: nginx-config-volume
		      configMap:
		        name: nginx-config
		  containers:
		    - name: nginx-container
		      image: nginx:latest
		      volumeMounts:
		        - name: shared-files
		          mountPath: /var/www/html
		        - name: nginx-config-volume
		          mountPath: /etc/nginx/nginx.conf
		          subPath: nginx.conf
		    - name: php-fpm-container
		      image: php:7.3-fpm
		      volumeMounts:
		        - name: shared-files
		          mountPath: /var/www/html

		#Service configuration
		---
		apiVersion: v1
		kind: Service
		metadata:
		  name: nginx-phpfpm
		spec:
		  type: NodePort
		  selector:
		    app: nginx-phpfpm
		    tier: back-end
		  ports:
		    - port: 8091
		      targetPort: 8091
		      nodePort: 30012

3. Create the service and pods

thor@jump_host ~$ kubectl create -f /tmp/nginx_phpfpm.yml 
		configmap/nginx-config created
		pod/nginx-phpfpm created
		service/nginx-phpfpm created

4. Check the configuration applied and wait for pod to get running  

thor@jump_host ~$ kubectl get all
		NAME               READY   STATUS              RESTARTS   AGE
		pod/nginx-phpfpm   0/2     ContainerCreating   0          10s

		NAME                   TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE
		service/kubernetes     ClusterIP   10.96.0.1     <none>        443/TCP          5h11m
		service/nginx-phpfpm   NodePort    10.96.77.59   <none>        8091:30012/TCP   10s
 
thor@jump_host ~$ kubectl get all
		NAME               READY   STATUS    RESTARTS   AGE
		pod/nginx-phpfpm   2/2     Running   0          60s

		NAME                   TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE
		service/kubernetes     ClusterIP   10.96.0.1     <none>        443/TCP          5h12m
		service/nginx-phpfpm   NodePort    10.96.77.59   <none>        8091:30012/TCP   60s

5. Copy the mentioned file in the given pod

thor@jump_host ~$ kubectl cp /opt/index.php nginx-phpfpm:/var/www/html --container=nginx-container

6. Validate by clicking on the App Button top right side side of the terminal. If the app is running then the task is done.

--------------------------------------------------------------------------------------------------------------------------------
Task 102: 18/Nov/2022

Run a Docker Container


Nautilus DevOps team is testing some applications deployment on some of the application servers. They need to deploy a nginx container on Application Server 3. Please complete the task as per details given below:

    On Application Server 3 create a container named nginx_3 using image nginx with alpine tag and make sure container is in running state.

1.Login to app server 3 and switch to root user 

thor@jump_host ~$ ssh banner@stapp03
		The authenticity of host 'stapp03 (172.16.238.12)' can't be established.
		ECDSA key fingerprint is SHA256:Zf7WuEVcvpXAR1ITq9DoENoxEcCaCyV0Y4JyuAJXgFc.
		ECDSA key fingerprint is MD5:48:49:21:90:b7:aa:00:ed:df:0f:a2:fb:b0:5d:92:8f.
		Are you sure you want to continue connecting (yes/no)? yes
		Warning: Permanently added 'stapp03,172.16.238.12' (ECDSA) to the list of known hosts.
		banner@stapp03's password: 

[banner@stapp03 ~]$ sudo su -

		We trust you have received the usual lecture from the local System
		Administrator. It usually boils down to these three things:

		    #1) Respect the privacy of others.
		    #2) Think before you type.
		    #3) With great power comes great responsibility.

		[sudo] password for banner: 

2. Check existing running docker images and containers

[root@stapp03 ~]# docker ps
		CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES

[root@stapp03 ~]# docker images
		REPOSITORY   TAG       IMAGE ID   CREATED   SIZE

3. Run the docker container as per requirement using the given image and name  

[root@stapp03 ~]# docker run -d --name nginx_3 -p 8080:80 nginx:alpine
		Unable to find image 'nginx:alpine' locally
		alpine: Pulling from library/nginx
		ca7dd9ec2225: Pull complete 
		76a48b0f5898: Pull complete 
		2f12a0e7c01d: Pull complete 
		1a7b9b9bbef6: Pull complete 
		b704883c57af: Pull complete 
		4342b1ab302e: Pull complete 
		Digest: sha256:455c39afebd4d98ef26dd70284aa86e6810b0485af5f4f222b19b89758cabf1e
		Status: Downloaded newer image for nginx:alpine
		d022a38a3abd331cea55f3b89f1da16373a3b58d34f9f6d08d554c37545554a5

4. Check the docker running status

[root@stapp03 ~]# docker ps
		CONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS         PORTS                  NAMES
		d022a38a3abd   nginx:alpine   "/docker-entrypoint."   8 seconds ago   Up 5 seconds   0.0.0.0:8080->80/tcp   nginx_3

[root@stapp03 ~]# docker images
		REPOSITORY   TAG       IMAGE ID       CREATED      SIZE
		nginx        alpine    19dd4d73108a   6 days ago   23.5MB

5. Validate by clicking on the view port top right side side of the terminal and select port 80. If the container is running then we see nginx page and the task is done.

--------------------------------------------------------------------------------------------------------------------------------
Task 103: 20/Nov/2022

Git Create Branches

Nautilus developers are actively working on one of the project repositories, /usr/src/kodekloudrepos/apps. They recently decided to implement some new features in the application, and they want to maintain those new changes in a separate branch. Below are the requirements that have been shared with the DevOps team:

    On Storage server in Stratos DC create a new branch xfusioncorp_apps from master branch in /usr/src/kodekloudrepos/apps git repo.

    Please do not try to make any changes in code.


1. Login to Storage server and switch to root user 

thor@jump_host ~$ ssh natasha@ststor01
		The authenticity of host 'ststor01 (172.16.238.15)' can't be established.
		ECDSA key fingerprint is SHA256:bNwXFd+JrQ3QZwtPJNbAxE+nIRPwx+rAC8iwQL2UNUs.
		ECDSA key fingerprint is MD5:a1:23:7e:da:b3:40:86:fc:22:47:b7:f1:15:7d:ab:b3.
		Are you sure you want to continue connecting (yes/no)? yes
		Warning: Permanently added 'ststor01,172.16.238.15' (ECDSA) to the list of known hosts.
		natasha@ststor01's password: 

[natasha@ststor01 ~]$ sudo su - 

		We trust you have received the usual lecture from the local System
		Administrator. It usually boils down to these three things:

		    #1) Respect the privacy of others.
		    #2) Think before you type.
		    #3) With great power comes great responsibility.

		[sudo] password for natasha: 

2. Go to mentioned repository
[root@ststor01 ~]# cd /usr/src/kodekloudrepos/apps/

3. List current branches

[root@ststor01 apps]# git branch -a
		* kodekloud_apps
		  master
		  remotes/origin/master

4. Switch to master branch as we are required to create new branch from master 

[root@ststor01 apps]# git checkout master
		Switched to branch 'master'

[root@ststor01 apps]# git branch -a
		  kodekloud_apps
		* master
		  remotes/origin/master

[root@ststor01 apps]# git status
		# On branch master
		nothing to commit, working directory clean

5. Create the mentioned branch and checkout to it .

[root@ststor01 apps]# git branch xfusioncorp_apps
 
[root@ststor01 apps]# git checkout xfusioncorp_apps
		Switched to branch 'xfusioncorp_apps'

6. Validate the task 

[root@ststor01 apps]# git branch -a
		  kodekloud_apps
		  master
		* xfusioncorp_apps
		  remotes/origin/master

[root@ststor01 apps]# git status
		# On branch xfusioncorp_apps
		nothing to commit, working directory clean

--------------------------------------------------------------------------------------------------------------------------------
Task 104: 28/Nov/2022

Kubernetes Troubleshooting

One of the Nautilus DevOps team members was working on to update an existing Kubernetes template. Somehow, he made some mistakes in the template and it is failing while applying. We need to fix this as soon as possible, so take a look into it and make sure you are able to apply it without any issues. Also, do not remove any component from the template like pods/deployments/volumes etc.

/home/thor/mysql_deployment.yml is the template that needs to be fixed.

Note: The kubectl utility on jump_host has been configured to work with the kubernetes cluster.


thor@jump_host ~$ pwd 
		/home/thor
thor@jump_host ~$ ls -ahl
		total 36K
		drwxr----- 1 thor thor 4.0K Nov 28 02:58 .
		drwxr-xr-x 1 root root 4.0K Oct 31  2020 ..
		-rwxrwx--- 1 thor thor   18 Oct 30  2018 .bash_logout
		-rwxrwx--- 1 thor thor  193 Oct 30  2018 .bash_profile
		-rwxrwx--- 1 thor thor  510 Nov 28 02:58 .bashrc
		drwxrwx--- 1 thor thor 4.0K Oct 31  2020 .config
		drwxrwx--- 2 thor thor 4.0K Nov 28 02:58 .kube
		-rw-r--r-- 1 thor thor 2.3K Nov 28 02:58 mysql_deployment.yml
		drwx------ 2 thor thor 4.0K Nov 28 02:58 .ssh

thor@jump_host ~$ kubectl get all
		NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
		service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6h6m
 
thor@jump_host ~$ kubectl get secrets
		NAME                  TYPE                                  DATA   AGE
		default-token-z8mrm   kubernetes.io/service-account-token   3      6h6m
		mysql-db-url          Opaque                                1      37s
		mysql-root-pass       Opaque                                1      38s
		mysql-user-pass       Opaque                                2      37s
 
thor@jump_host ~$ cat mysql_deployment.yml 
		apiVersion: apps/v1 
		kind: PersistentVolume            
		metadata:
		  name: mysql-pv
		  labels: 
		  type: local 
		spec:
		  storageClassName: standard      
		  capacity:
		    storage: 250Mi
		  accessModes: 
		    - ReadWriteOnce
		  hostPath:                       
		  path: "/mnt/data" 
		  persistentVolumeReclaimPolicy:  
		  -  Retain  
		---    
		apiVersion: apps/v1 
		kind: PersistentVolumeClaim 
		metadata:                          
		  name: mysql-pv-claim
		  labels:
		  app: mysql-app 
		spec:                              
		  storageClassName: standard       
		  accessModes:
		    - ReadWriteOnce                
		  resources:
		    requests: 
		      storage: 250MB 
		---
		apiVersion: v1                    
		kind: Service                      
		metadata:
		  name: mysql         
		  labels:             
		    app: mysql-app
		spec:
		  type: NodePort
		  ports:
		    - targetPort: 3306
		      port: 3306
		      nodePort: 30011
		  selector:    
		    app: mysql-app
		  tier: mysql
		---
		apiVersion: v1 
		kind: Deployment            
		metadata:
		  name: mysql-deployment       
		  labels:                       
		    app: mysql-app 
		spec:
		  selector:
		    matchLabels:
		      app: mysql-app
		    tier: mysql 
		  strategy:
		    type: Recreate
		  template:                    
		    metadata:
		      labels:                  
		        app: mysql-app
		      tier: mysql 
		    spec:                       
		      containers: 
		      - images: mysql:5.6 
		        name: mysql
		        env:                        
		        - name: MYSQL_ROOT_PASSWORD 
		          valueFrom:                
		          secretKeyRef: 
		            name: mysql-root-pass 
		              key: password 
		        - name: MYSQL_DATABASE
		          valueFrom:
		          secretKeyRef: 
		            name: mysql-db-url 
		              key: database 
		        - name: MYSQL_USER
		          valueFrom:
		            secretKeyRef:
		              name: mysql-user-pass
		              key: username
		        - name: MYSQL_PASSWORD
		          valueFrom:
		            secretKeyRef:
		              name: mysql-user-pass
		              key: password
		        ports:
		        - containerPort: 3306        
		          name: mysql
		        volumeMounts:
		        - name: mysql-persistent-storage 
		          mountPath: /var/lib/mysql
		      volumes:                       
		      - name: mysql-persistent-storage
		          persistentVolumeClaim:
		          claimName: mysql-pv-claim

thor@jump_host ~$ kubectl create -f mysql_deployment.yml 
		unable to recognize "mysql_deployment.yml": no matches for kind "PersistentVolume" in version "apps/v1"
		unable to recognize "mysql_deployment.yml": no matches for kind "PersistentVolumeClaim" in version "apps/v1"
		error validating "mysql_deployment.yml": error validating data: ValidationError(Service.spec): unknown field "tier" in io.k8s.api.core.v1.ServiceSpec; if you choose to ignore these errors, turn validation off with --validate=false


thor@jump_host ~$ vi mysql_pv.yml
thor@jump_host ~$ cat mysql_pv.yml
		---
		apiVersion: apps/v1 
		kind: PersistentVolume            
		metadata:
		  name: mysql-pv
		  labels: 
		  type: local 
		spec:
		  storageClassName: standard      
		  capacity:
		    storage: 250Mi
		  accessModes: 
		    - ReadWriteOnce
		  hostPath:                       
		  path: "/mnt/data" 
		  persistentVolumeReclaimPolicy:  
		  -  Retain  

thor@jump_host ~$ kubectl create -f mysql_pv.yml 
		error: unable to recognize "mysql_pv.yml": no matches for kind "PersistentVolume" in version "apps/v1"

thor@jump_host ~$ vi mysql_pv.yml
thor@jump_host ~$ cat mysql_pv.yml
		---
		apiVersion: v1 
		kind: PersistentVolume            
		metadata:
		  name: mysql-pv
		  labels: 
		  type: local 
		spec:
		  storageClassName: standard      
		  capacity:
		    storage: 250Mi
		  accessModes: 
		  - ReadWriteOnce
		  hostPath:                       
		    path: "/mnt/data" 
		  persistentVolumeReclaimPolicy: Retain  

thor@jump_host ~$ kubectl create -f mysql_pv.yml 
		error: error validating "mysql_pv.yml": error validating data: ValidationError(PersistentVolume.metadata): unknown field "type" in io.k8s.apimachinery.pkg.apis.meta.v1.ObjectMeta; if you choose to ignore these errors, turn validation off with --validate=false

thor@jump_host ~$ vi mysql_pv.yml
thor@jump_host ~$ cat mysql_pv.yml
		---
		apiVersion: v1 																																										<---------------
		kind: PersistentVolume            
		metadata:
		  name: mysql-pv
		  labels: 
		    type: local 																																									<---------------
		spec:
		  storageClassName: standard      
		  capacity:
		    storage: 250Mi
		  accessModes: 
		  - ReadWriteOnce																																									<---------------
		  hostPath:                       
		    path: "/mnt/data" 
		  persistentVolumeReclaimPolicy: Retain 																													<--------------- 

thor@jump_host ~$ kubectl create -f mysql_pv.yml 
		persistentvolume/mysql-pv created
 
thor@jump_host ~$ vi mysql_pvc.yml
thor@jump_host ~$ cat mysql_pvc.yml
		---    
		apiVersion: apps/v1 
		kind: PersistentVolumeClaim 
		metadata:                          
		  name: mysql-pv-claim
		  labels:
		  app: mysql-app 
		spec:                              
		  storageClassName: standard       
		  accessModes:
		    - ReadWriteOnce                
		  resources:
		    requests: 
		      storage: 250MB 

thor@jump_host ~$ kubectl create -f  mysql_pvc.yml
		error: unable to recognize "mysql_pvc.yml": no matches for kind "PersistentVolumeClaim" in version "apps/v1"

thor@jump_host ~$ vi mysql_pvc.yml
thor@jump_host ~$ cat mysql_pvc.yml
		---    
		apiVersion: v1 																																									<---------------
		kind: PersistentVolumeClaim 
		metadata:                          
		  name: mysql-pv-claim
		  labels:
		    app: mysql-app 																																							<---------------
		spec:                              
		  storageClassName: standard       
		  accessModes:
		  - ReadWriteOnce 																																							<---------------               
		  resources:
		    requests: 
		      storage: 250Mi 																																						<---------------

thor@jump_host ~$ kubectl create -f  mysql_pvc.yml
		persistentvolumeclaim/mysql-pv-claim created
 
thor@jump_host ~$ vi mysql_service.yml
thor@jump_host ~$ cat mysql_service.yml
		---
		apiVersion: v1                    
		kind: Service                      
		metadata:
		  name: mysql         
		  labels:             
		    app: mysql-app
		spec:
		  type: NodePort
		  ports:
		    - targetPort: 3306
		      port: 3306
		      nodePort: 30011
		  selector:    
		    app: mysql-app
		  tier: mysql

thor@jump_host ~$ kubectl create -f mysql_service.yml
		error: error validating "mysql_service.yml": error validating data: ValidationError(Service.spec): unknown field "tier" in io.k8s.api.core.v1.ServiceSpec; if you choose to ignore these errors, turn validation off with --validate=false

thor@jump_host ~$ vi mysql_service.yml
thor@jump_host ~$ cat mysql_service.yml
		---
		apiVersion: v1                    
		kind: Service                      
		metadata:
		  name: mysql         
		  labels:             
		    app: mysql-app
		spec:
		  type: NodePort
		  ports:
		    - targetPort: 3306
		      port: 3306
		      nodePort: 30011
		  selector:    
		    app: mysql-app
		    tier: mysql 																																							<---------------																						
thor@jump_host ~$ kubectl create -f mysql_service.yml
		service/mysql created

thor@jump_host ~$ vi mysql_deploy.yml
thor@jump_host ~$ cat mysql_deploy.yml
		---
		apiVersion: v1 
		kind: Deployment            
		metadata:
		  name: mysql-deployment       
		  labels:                       
		    app: mysql-app 
		spec:
		  selector:
		    matchLabels:
		      app: mysql-app
		    tier: mysql 
		  strategy:
		    type: Recreate
		  template:                    
		    metadata:
		      labels:                  
		        app: mysql-app
		      tier: mysql 
		    spec:                       
		      containers: 
		      - images: mysql:5.6 
		        name: mysql
		        env:                        
		        - name: MYSQL_ROOT_PASSWORD 
		          valueFrom:                
		          secretKeyRef: 
		            name: mysql-root-pass 
		              key: password 
		        - name: MYSQL_DATABASE
		          valueFrom:
		          secretKeyRef: 
		            name: mysql-db-url 
		              key: database 
		        - name: MYSQL_USER
		          valueFrom:
		            secretKeyRef:
		              name: mysql-user-pass
		              key: username
		        - name: MYSQL_PASSWORD
		          valueFrom:
		            secretKeyRef:
		              name: mysql-user-pass
		              key: password
		        ports:
		        - containerPort: 3306        
		          name: mysql
		        volumeMounts:
		        - name: mysql-persistent-storage 
		          mountPath: /var/lib/mysql
		      volumes:                       
		      - name: mysql-persistent-storage
		          persistentVolumeClaim:
		          claimName: mysql-pv-claim

thor@jump_host ~$ kubectl create -f mysql_deploy.yml
		error: error parsing mysql_deploy.yml: error converting YAML to JSON: yaml: line 29: mapping values are not allowed in this context

thor@jump_host ~$ vi mysql_deploy.yml
thor@jump_host ~$ cat mysql_deploy.yml
		---
		apiVersion: v1 
		kind: Deployment            
		metadata:
		  name: mysql-deployment       
		  labels:                       
		    app: mysql-app 
		spec:
		  selector:
		    matchLabels:
		      app: mysql-app
		      tier: mysql 
		  strategy:
		    type: Recreate
		  template:                    
		    metadata:
		      labels:                  
		        app: mysql-app
		        tier: mysql 
		    spec:                       
		      containers: 
		      - images: mysql:5.6 
		        name: mysql
		        env:                        
		        - name: MYSQL_ROOT_PASSWORD 
		          valueFrom:                
		            secretKeyRef: 
		              name: mysql-root-pass 
		              key: password 
		        - name: MYSQL_DATABASE
		          valueFrom:
		            secretKeyRef: 
		              name: mysql-db-url 
		              key: database 
		        - name: MYSQL_USER
		          valueFrom:
		            secretKeyRef:
		              name: mysql-user-pass
		              key: username
		        - name: MYSQL_PASSWORD
		          valueFrom:
		            secretKeyRef:
		              name: mysql-user-pass
		              key: password
		        ports:
		        - containerPort: 3306        
		          name: mysql
		        volumeMounts:
		        - name: mysql-persistent-storage 
		          mountPath: /var/lib/mysql
		      volumes:                       
		      - name: mysql-persistent-storage
		        persistentVolumeClaim:
		          claimName: mysql-pv-claim

thor@jump_host ~$ kubectl create -f mysql_deploy.yml
		error: unable to recognize "mysql_deploy.yml": no matches for kind "Deployment" in version "v1"

thor@jump_host ~$ vi mysql_deploy.yml

thor@jump_host ~$ kubectl create -f mysql_deploy.yml
		error: error validating "mysql_deploy.yml": error validating data: ValidationError(Deployment.spec.template.spec.containers[0]): unknown field "images" in io.k8s.api.core.v1.Container; if you choose to ignore these errors, turn validation off with --validate=false

thor@jump_host ~$ vi mysql_deploy.yml
thor@jump_host ~$ cat mysql_deploy.yml
		---
		apiVersion: apps/v1 																																	<---------------				
		kind: Deployment            
		metadata:
		  name: mysql-deployment       
		  labels:                       
		    app: mysql-app 
		spec:
		  selector:
		    matchLabels:
		      app: mysql-app
		      tier: mysql 																																		<---------------					
		  strategy:
		    type: Recreate
		  template:                    
		    metadata:
		      labels:                  
		        app: mysql-app
		        tier: mysql 
		    spec:                       
		      containers: 
		      - image: mysql:5.6 																															<---------------		
		        name: mysql
		        env:                        
		        - name: MYSQL_ROOT_PASSWORD 
		          valueFrom:                
		            secretKeyRef: 																														<---------------
		              name: mysql-root-pass 																									<---------------		
		              key: password 
		        - name: MYSQL_DATABASE
		          valueFrom:
		            secretKeyRef: 																														<---------------				
		              name: mysql-db-url 																											<---------------
		              key: database 
		        - name: MYSQL_USER
		          valueFrom:
		            secretKeyRef:
		              name: mysql-user-pass
		              key: username
		        - name: MYSQL_PASSWORD
		          valueFrom:
		            secretKeyRef:
		              name: mysql-user-pass
		              key: password
		        ports:
		        - containerPort: 3306        
		          name: mysql
		        volumeMounts:
		        - name: mysql-persistent-storage 
		          mountPath: /var/lib/mysql
		      volumes:                       
		      - name: mysql-persistent-storage
		        persistentVolumeClaim:																												<---------------			
		          claimName: mysql-pv-claim

thor@jump_host ~$ kubectl create -f mysql_deploy.yml
		deployment.apps/mysql-deployment created

 
thor@jump_host ~$ kubectl get all
		NAME                                    READY   STATUS              RESTARTS   AGE
		pod/mysql-deployment-74f5dd5cdf-gq5nd   0/1     ContainerCreating   0          13s

		NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
		service/kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP          6h23m
		service/mysql        NodePort    10.96.153.164   <none>        3306:30011/TCP   10m

		NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
		deployment.apps/mysql-deployment   0/1     1            0           13s

		NAME                                          DESIRED   CURRENT   READY   AGE
		replicaset.apps/mysql-deployment-74f5dd5cdf   1         1         0       13s

thor@jump_host ~$ kubectl get pv
		NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                    STORAGECLASS   REASON   AGE
		mysql-pv   250Mi      RWO            Retain           Bound    default/mysql-pv-claim   standard                13m

thor@jump_host ~$ kubectl get pvc
		NAME             STATUS   VOLUME     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
		mysql-pv-claim   Bound    mysql-pv   250Mi      RWO            standard       12m
 
thor@jump_host ~$ kubectl get all
		NAME                                    READY   STATUS    RESTARTS   AGE
		pod/mysql-deployment-74f5dd5cdf-gq5nd   1/1     Running   0          36s

		NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
		service/kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP          6h24m
		service/mysql        NodePort    10.96.153.164   <none>        3306:30011/TCP   10m

		NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
		deployment.apps/mysql-deployment   1/1     1            1           36s

		NAME                                          DESIRED   CURRENT   READY   AGE
		replicaset.apps/mysql-deployment-74f5dd5cdf   1         1         1       36s
 
thor@jump_host ~$ kubectl delete service mysql
		service "mysql" deleted

thor@jump_host ~$ kubectl get all
		NAME                                    READY   STATUS    RESTARTS   AGE
		pod/mysql-deployment-74f5dd5cdf-gq5nd   1/1     Running   0          69s

		NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
		service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6h24m

		NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
		deployment.apps/mysql-deployment   1/1     1            1           69s

		NAME                                          DESIRED   CURRENT   READY   AGE
		replicaset.apps/mysql-deployment-74f5dd5cdf   1         1         1       69s

thor@jump_host ~$ kubectl delete deployment mysql-deployment
		deployment.apps "mysql-deployment" deleted

thor@jump_host ~$ kubectl get all
		NAME                                    READY   STATUS        RESTARTS   AGE
		pod/mysql-deployment-74f5dd5cdf-gq5nd   0/1     Terminating   0          106s

		NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
		service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6h25m

thor@jump_host ~$ kubectl delete pods mysql-deployment-74f5dd5cdf-gq5nd
		Error from server (NotFound): pods "mysql-deployment-74f5dd5cdf-gq5nd" not found
thor@jump_host ~$ kubectl get all
		NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
		service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6h26m
 
thor@jump_host ~$ kubectl delete pvc mysql-pv-claim
		persistentvolumeclaim "mysql-pv-claim" deleted

thor@jump_host ~$ kubectl delete pv mysql-pv
		persistentvolume "mysql-pv" deleted
 
thor@jump_host ~$ kubectl get pv 
		No resources found
thor@jump_host ~$ kubectl get pvc
		No resources found in default namespace.

thor@jump_host ~$ cp mysql_deployment.yml mysql_deployment_bkp.yml
thor@jump_host ~$ vi mysql_deployment.yml 
thor@jump_host ~$ cat mysql_pv.yml mysql_pvc.yml mysql_service.yml mysql_deploy.yml >> mysql_deployment.yml 
thor@jump_host ~$ cat mysql_deployment.yml 
---
apiVersion: v1 
kind: PersistentVolume            
metadata:
  name: mysql-pv
  labels: 
    type: local 
spec:
  storageClassName: standard      
  capacity:
    storage: 250Mi
  accessModes: 
  - ReadWriteOnce
  hostPath:                       
    path: "/mnt/data" 
  persistentVolumeReclaimPolicy: Retain  
---    
apiVersion: v1 
kind: PersistentVolumeClaim 
metadata:                          
  name: mysql-pv-claim
  labels:
    app: mysql-app 
spec:                              
  storageClassName: standard       
  accessModes:
  - ReadWriteOnce                
  resources:
    requests: 
      storage: 250Mi 
---
apiVersion: v1                    
kind: Service                      
metadata:
  name: mysql         
  labels:             
    app: mysql-app
spec:
  type: NodePort
  ports:
    - targetPort: 3306
      port: 3306
      nodePort: 30011
  selector:    
    app: mysql-app
    tier: mysql
---
apiVersion: apps/v1 
kind: Deployment            
metadata:
  name: mysql-deployment       
  labels:                       
    app: mysql-app 
spec:
  selector:
    matchLabels:
      app: mysql-app
      tier: mysql 
  strategy:
    type: Recreate
  template:                    
    metadata:
      labels:                  
        app: mysql-app
        tier: mysql 
    spec:                       
      containers: 
      - image: mysql:5.6 
        name: mysql
        env:                        
        - name: MYSQL_ROOT_PASSWORD 
          valueFrom:                
            secretKeyRef: 
              name: mysql-root-pass 
              key: password 
        - name: MYSQL_DATABASE
          valueFrom:
            secretKeyRef: 
              name: mysql-db-url 
              key: database 
        - name: MYSQL_USER
          valueFrom:
            secretKeyRef:
              name: mysql-user-pass
              key: username
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-user-pass
              key: password
        ports:
        - containerPort: 3306        
          name: mysql
        volumeMounts:
        - name: mysql-persistent-storage 
          mountPath: /var/lib/mysql
      volumes:                       
      - name: mysql-persistent-storage
        persistentVolumeClaim:
          claimName: mysql-pv-claim

thor@jump_host ~$ ls -ahl
total 56K
		drwxr----- 1 thor thor 4.0K Nov 28 03:21 .
		drwxr-xr-x 1 root root 4.0K Oct 31  2020 ..
		-rwxrwx--- 1 thor thor   18 Oct 30  2018 .bash_logout
		-rwxrwx--- 1 thor thor  193 Oct 30  2018 .bash_profile
		-rwxrwx--- 1 thor thor  510 Nov 28 02:58 .bashrc
		drwxrwx--- 1 thor thor 4.0K Oct 31  2020 .config
		drwxrwx--- 3 thor thor 4.0K Nov 28 02:59 .kube
		-rw-r--r-- 1 thor thor 2.3K Nov 28 03:20 mysql_deployment_bkp.yml
		-rw-r--r-- 1 thor thor 2.3K Nov 28 03:21 mysql_deployment.yml
		-rw-rw-r-- 1 thor thor 1.4K Nov 28 03:16 mysql_deploy.yml
		-rw-rw-r-- 1 thor thor  313 Nov 28 03:04 mysql_pvc.yml
		-rw-rw-r-- 1 thor thor  316 Nov 28 03:02 mysql_pv.yml
		-rw-rw-r-- 1 thor thor  295 Nov 28 03:06 mysql_service.yml
		drwx------ 2 thor thor 4.0K Nov 28 02:58 .ssh

thor@jump_host ~$ kubectl create -f mysql_deployment.yml 
		persistentvolume/mysql-pv created
		persistentvolumeclaim/mysql-pv-claim created
		service/mysql created
		deployment.apps/mysql-deployment created
 
thor@jump_host ~$ kubectl get all
		NAME                                    READY   STATUS    RESTARTS   AGE
		pod/mysql-deployment-74f5dd5cdf-cqwt6   1/1     Running   0          7s

		NAME                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
		service/kubernetes   ClusterIP   10.96.0.1      <none>        443/TCP          6h29m
		service/mysql        NodePort    10.96.176.41   <none>        3306:30011/TCP   7s

		NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
		deployment.apps/mysql-deployment   1/1     1            1           7s

		NAME                                          DESIRED   CURRENT   READY   AGE
		replicaset.apps/mysql-deployment-74f5dd5cdf   1         1         1       7s

thor@jump_host ~$ kubectl get pv
		NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                    STORAGECLASS   REASON   AGE
		mysql-pv   250Mi      RWO            Retain           Bound    default/mysql-pv-claim   standard                16s

thor@jump_host ~$ kubectl get pvc
		NAME             STATUS   VOLUME     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
		mysql-pv-claim   Bound    mysql-pv   250Mi      RWO            standard       19s
thor@jump_host ~$ 

--------------------------------------------------------------------------------------------------------------------------------
Task 105: 29/Nov/2022

Save, Load and Transfer Docker Image

One of the DevOps team members was working on to create a new custom docker image on App Server 1 in Stratos DC. He is done with his changes and image is saved on same server with name demo:nautilus. Recently a requirement has been raised by a team to use that image for testing, but the team wants to test the same on App Server 3. So we need to provide them that image on App Server 3 in Stratos DC.

a. On App Server 1 save the image demo:nautilus in an archive.

b. Transfer the image archive to App Server 3.

c. Load that image archive on App Server 3 with same name and tag which was used on App Server 1.

Note: Docker is already installed on both servers; however, if its service is down please make sure to start it.

1. Login to App Server and switch to root

thor@jump_host ~$ ssh tony@stapp01
		The authenticity of host 'stapp01 (172.16.238.10)' can't be established.
		ECDSA key fingerprint is SHA256:7/VTPQ2CABk+3zUB7pJzVmT/d4XiNBJuNZ0bl5GCobQ.
		ECDSA key fingerprint is MD5:df:68:3b:89:1a:b0:fd:1f:79:ec:d4:b7:89:e3:e9:13.
		Are you sure you want to continue connecting (yes/no)? yes
		Warning: Permanently added 'stapp01,172.16.238.10' (ECDSA) to the list of known hosts.
		tony@stapp01's password: 

[tony@stapp01 ~]$ sudo su -

		We trust you have received the usual lecture from the local System
		Administrator. It usually boils down to these three things:

		    #1) Respect the privacy of others.
		    #2) Think before you type.
		    #3) With great power comes great responsibility.

		[sudo] password for tony: 

2. List the existing images in docker which need to archive

[root@stapp01 ~]# docker images
		REPOSITORY   TAG        IMAGE ID       CREATED              SIZE
		demo         nautilus   a0358bd5cf49   About a minute ago   118MB
		ubuntu       latest     a8780b506fa4   3 weeks ago          77.8MB

3. Save the image in a TAR archive

[root@stapp01 ~]# docker save -o /tmp/demo.tar demo:nautilus

[root@stapp01 ~]# ls -ahl /tmp
		total 115M
		drwxrwxrwt 1 root root 4.0K Nov 29 04:40 .
		drwxr-xr-x 1 root root 4.0K Nov 29 04:36 ..
		-rw------- 1 root root 115M Nov 29 04:40 demo.tar
		-rwxr-xr-x 1 root root  239 Nov 29 04:37 docker_container.sh
		drwxrwxrwt 1 root root 4.0K Aug  1  2019 .font-unix
		drwxrwxrwt 1 root root 4.0K Aug  1  2019 .ICE-unix
		-rwx------ 1 root root  836 Aug  1  2019 ks-script-rnBCJB
		drwxrwxrwt 1 root root 4.0K Aug  1  2019 .Test-unix
		drwxrwxrwt 1 root root 4.0K Aug  1  2019 .X11-unix
		drwxrwxrwt 1 root root 4.0K Aug  1  2019 .XIM-unix
		-rw------- 1 root root    0 Aug  1  2019 yum.log

4. Copy(SCP) the archive file to mentioned server

[root@stapp01 ~]# scp /tmp/demo.tar banner@stapp03:/tmp
		The authenticity of host 'stapp03 (172.16.238.12)' can't be established.
		ECDSA key fingerprint is SHA256:RveOEHTizfGCH1Dwm9qbs1/OPlyAGQuSYS3JGfpEwL0.
		ECDSA key fingerprint is MD5:13:5d:0c:a2:b4:72:84:a9:15:41:8e:35:a6:f3:7f:22.
		Are you sure you want to continue connecting (yes/no)? yes
		Warning: Permanently added 'stapp03,172.16.238.12' (ECDSA) to the list of known hosts.
		banner@stapp03's password: 
		demo.tar                                                                                                   100%  115MB  45.8MB/s   00:02    

5. Login to mentioned App server and switch to root user

[root@stapp01 ~]# ssh banner@stapp03
		banner@stapp03's password: 
 
[banner@stapp03 ~]$ sudo su  -

		We trust you have received the usual lecture from the local System
		Administrator. It usually boils down to these three things:

		    #1) Respect the privacy of others.
		    #2) Think before you type.
		    #3) With great power comes great responsibility.

		[sudo] password for banner: 

6. Verify the copied archive file

[root@stapp03 ~]# ls -ahl /tmp/
		total 115M
		drwxrwxrwt 1 root   root   4.0K Nov 29 04:41 .
		drwxr-xr-x 1 root   root   4.0K Nov 29 04:36 ..
		-rw------- 1 banner banner 115M Nov 29 04:41 demo.tar
		drwxrwxrwt 1 root   root   4.0K Aug  1  2019 .font-unix
		drwxrwxrwt 1 root   root   4.0K Aug  1  2019 .ICE-unix
		-rwx------ 1 root   root    836 Aug  1  2019 ks-script-rnBCJB
		drwxrwxrwt 1 root   root   4.0K Aug  1  2019 .Test-unix
		drwxrwxrwt 1 root   root   4.0K Aug  1  2019 .X11-unix
		drwxrwxrwt 1 root   root   4.0K Aug  1  2019 .XIM-unix
		-rw------- 1 root   root      0 Aug  1  2019 yum.log

7. Check current docker images
[root@stapp03 ~]# docker images
		Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?

8. Start docker daemon if required 

[root@stapp03 ~]# systemctl start docker

[root@stapp03 ~]# systemctl status docker
		 docker.service - Docker Application Container Engine
		   Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled)
		   Active: active (running) since Tue 2022-11-29 04:42:59 UTC; 7s ago
		     Docs: https://docs.docker.com
		 Main PID: 583 (dockerd)
		    Tasks: 23
		   Memory: 49.2M
		   CGroup: /docker/dcc4ae04d8c1008c63da5958d22da0d318642b6438e34301f6634af45e159a3c/system.slice/docker.service
		           583 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock

		Nov 29 04:42:57 stapp03.stratos.xfusioncorp.com dockerd[583]: time="2022-11-29T04:42:57.326955764Z" level=warning msg="Your kernel do...imit"
		Nov 29 04:42:57 stapp03.stratos.xfusioncorp.com dockerd[583]: time="2022-11-29T04:42:57.327031003Z" level=warning msg="Your kernel do...uler"
		Nov 29 04:42:57 stapp03.stratos.xfusioncorp.com dockerd[583]: time="2022-11-29T04:42:57.327039173Z" level=warning msg="Your kernel do...ight"
		Nov 29 04:42:57 stapp03.stratos.xfusioncorp.com dockerd[583]: time="2022-11-29T04:42:57.327046428Z" level=warning msg="Your kernel do...vice"
		Nov 29 04:42:57 stapp03.stratos.xfusioncorp.com dockerd[583]: time="2022-11-29T04:42:57.330263079Z" level=info msg="Loading container...art."
		Nov 29 04:42:58 stapp03.stratos.xfusioncorp.com dockerd[583]: time="2022-11-29T04:42:58.293270350Z" level=info msg="Loading container...one."
		Nov 29 04:42:58 stapp03.stratos.xfusioncorp.com dockerd[583]: time="2022-11-29T04:42:58.986622869Z" level=info msg="Docker daemon" co....10.7
		Nov 29 04:42:58 stapp03.stratos.xfusioncorp.com dockerd[583]: time="2022-11-29T04:42:58.986895666Z" level=info msg="Daemon has comple...tion"
		Nov 29 04:42:59 stapp03.stratos.xfusioncorp.com systemd[1]: Started Docker Application Container Engine.
		Nov 29 04:42:59 stapp03.stratos.xfusioncorp.com dockerd[583]: time="2022-11-29T04:42:59.681252769Z" level=info msg="API listen on /va...sock"
		Hint: Some lines were ellipsized, use -l to show in full.
 
[root@stapp03 ~]# docker images
		REPOSITORY   TAG       IMAGE ID   CREATED   SIZE

9. Load the image archive 

[root@stapp03 ~]# docker load -i /tmp/demo.tar 
		f4a670ac65b6: Loading layer [==================================================>]  80.31MB/80.31MB
		f1e0d34b5503: Loading layer [==================================================>]   39.8MB/39.8MB
		Loaded image: demo:nautilus

10. Validate the task by checking docker images

[root@stapp03 ~]# docker images
		REPOSITORY   TAG        IMAGE ID       CREATED         SIZE
		demo         nautilus   a0358bd5cf49   4 minutes ago   118MB

--------------------------------------------------------------------------------------------------------------------------------
Task 106:

--------------------------------------------------------------------------------------------------------------------------------
Task 107:

--------------------------------------------------------------------------------------------------------------------------------
Task 108:

--------------------------------------------------------------------------------------------------------------------------------
Task 109:

--------------------------------------------------------------------------------------------------------------------------------
Task 110:

--------------------------------------------------------------------------------------------------------------------------------
Task 111:

--------------------------------------------------------------------------------------------------------------------------------
Task 112:

--------------------------------------------------------------------------------------------------------------------------------
Task 113: